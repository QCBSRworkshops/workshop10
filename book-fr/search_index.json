[["index.html", "Atelier 10: Analyses multivariées avancées en R Série d’ateliers R du CSBQ Préface 0.1 Code de conduite 0.2 Contributeurs et contributrices 0.3 Contribuez à la série!", " Atelier 10: Analyses multivariées avancées en R Série d’ateliers R du CSBQ Développé et entretenu par les contributeurs et les contributrices de la Série d’ateliers R du CSBQ1. 2021-03-26 19:07:52 Préface La Série d’ateliers R du CSBQ est une série de 10 ateliers qui guide les participants à travers les étapes nécessaires à l’utilisation de R pour un large éventail d’analyses statistiques pertinentes pour la recherche en biologie et en écologie. Ces ateliers en accès libre ont été créés par des membres du CSBQ, à la fois pour les membres du CSBQ et pour la communauté au sens large. Le contenu de cet atelier a été revu par plusieurs membres du CSBQ. Si vous souhaitez suggérer des modifications, veuillez contacter les coordinateurs de la série actuelle, dont la liste figure sur la page principale de Github 0.1 Code de conduite La Série d’ateliers R du CSBQ et le Symposium R du CSBQ sont des lieux dédiés à fournir un environnement accueillant et favorable à toutes les personnes, indépendamment de leurs origines ou de leur identité. Les participants, les présentateurs et les organisateurs de la série d’ateliers et d’autres activités connexes acceptent le présent code de conduite lorsqu’ils assistent à des activités liées aux ateliers. Nous ne tolérons pas les comportements irrespectueux ou qui excluent, intimident ou gênent les autres. Nous ne tolérons pas la discrimination ou le harcèlement fondés sur des caractéristiques telles que, mais sans s’y limiter, l’identité et l’expression du genre, l’orientation sexuelle, le handicap, l’apparence physique, la taille du corps, la citoyenneté, la nationalité, les origines ethniques ou sociales, la grossesse, le statut familial, les informations génétiques, la religion ou les convictions (ou l’absence de celles-ci), l’appartenance à une minorité nationale, la propriété, l’âge, l’éducation, le statut socio-économique, les choix techniques et le niveau d’expérience. Il s’applique à tous les espaces gérés par l’atelier ou affiliés à celui-ci, y compris, mais sans s’y limiter, les ateliers, les listes de diffusion et les forums en ligne tels que GitHub, Slack et Twitter. 0.1.1 Comportement attendu Tous les participants sont tenus de faire preuve de respect et de courtoisie envers les autres. Toutes les interactions doivent être professionnelles, quelle que soit la plateforme utilisée : en ligne ou en personne. Afin de favoriser un environnement d’apprentissage positif et professionnel, nous encourageons les types de comportements suivants dans tous les événements et plates-formes des ateliers : Utiliser un langage accueillant et inclusif ; Respecter les différents points de vue et expériences ; Accepter avec grâce les critiques constructives ; Se concentrer sur ce qui est le mieux pour la communauté ; Faire preuve de courtoisie et de respect envers les autres membres de la communauté. 0.1.2 Comportements inacceptables Voici quelques exemples de comportements inacceptables de la part des participants à tout événement ou plateforme d’atelier : les commentaires écrits ou verbaux qui ont pour effet d’exclure des personnes sur la base de leur appartenance à un groupe spécifique ; faire craindre à quelqu’un pour sa sécurité, par exemple en le harcelant ou en l’intimidant ; des menaces ou des propos violents dirigés contre une autre personne ; l’affichage d’images sexuelles ou violentes ; l’attention sexuelle non désirée ; les contacts physiques non consensuels ou non désirés ; des insultes ou des rabais ; les blagues sexistes, racistes, homophobes, transphobes, incapables ou d’exclusion ; l’incitation à la violence, au suicide ou à l’automutilation ; la poursuite de l’interaction (y compris la photographie ou l’enregistrement) avec une personne après qu’on - lui a demandé d’arrêter ; la publication d’une communication privée sans consentement. 0.2 Contributeurs et contributrices Cette liste n’est pas finalisée. Si vous avez contribué à cet atelier et ne voyez pas votre nom, faites nous signe. Depuis 2014, plusieurs membres du CSBQ ont contribué à développer et à mettre à jour cet atelier de manière régulière et collaborative, dans le cadre de la bourse d’apprentissage et de développement (Learning and Development Award) du Centre québécois des sciences de la biodiversité. Développé à l’origine par: Monica Granados, Emmanuelle Chrétien, Bérenger Bourgeois, Amanda Winegardner, Xavier Giroux-Bougard, et Vincent Fugère. Contributions à la modification de la présentation : Gabriel Muñoz, Katherine Hébert, Kevin Cazelles, Pedro Henrique P. Braga, Marie Hélène Brice Contribution avec des changements à la documentation écrite : Marie Hélène Brice, Katherine Hébert Contribution en signalant des problèmes et en suggérant des modifications : Pedro Henrique P. Braga, Marie Hélène Brice, Kevin Cazelles 0.3 Contribuez à la série! La série d’ateliers R du CSBQ dépend sur les contributions des membres étudiants diplômés, postdoctoraux et professionnels de la recherche du CSBQ pour développer et présenter les ateliers. Nous sommes toujours à la recherche de contributeurs et contributrices pour amélorier le matériel et pour instruire les ateliers. Pour plus d’informations, nous vous invitons à consulter notre Protocole pour la présentation et le development. Si vous êtes intéressé(e)s à contribuer à la série d’ateliers, contactez-nous! Si vous trouvez des erreurs ou des incohérences, ou si vous souhaitez faire une suggestion, que ce soit sur la forme ou le contenu de ce matériel, vous êtes invités à ouvrir un numéro. Vous pouvez suivre ces étapes simples pour créer un nouveau numéro. La Série d’ateliers R du CSBQ fait partie du Centre de la science de la biodiversité du Québec, et est maintenue par les coordonnateurs et les coordonnatrices de la série, et les membres étudiants diplômés, postdoctoraux et professionnels de la recherche. La liste des contributeurs et des contributrices de cet atelier sont accessiblesici↩︎ "],["objectifs-dapprentissage.html", "Chapitre 1 Objectifs d’apprentissage", " Chapitre 1 Objectifs d’apprentissage Résumé: Durant cet atelier, vous apprendrez à réaliser des analyses multivariées avancées sur des données de communauté. Cet atelier se concentre sur les méthodes sous contraintes, telles que l’analyse canonique de redondances (RDA), l’arbre de régression multivarié (MRT) et l’analyse discriminante linéaire (LDA) afin d’explorer comment les variables environnementales peuvent expliquer les patrons de composition en espèces à travers différents sites. "],["préparez-vous-pour-cet-atelier.html", "Chapitre 2 Préparez-vous pour cet atelier", " Chapitre 2 Préparez-vous pour cet atelier Tout le matériel de l’atelier se trouve sur github.com/QCBSRworkshops/workshop10. Cela inclut un script R qui rassemble tous les morceaux de code présentés dans ce livre. Pour cet atelier, nous travaillerons avec les jeux de données suivants : DoubsEnv DoubsSpe DoubsSpa Données test pour l’analyse discriminante linéaire Pour télécharger ces données, faites un clic droit + enregistrer sur la page qui s’ouvre. Vous devriez également vous assurer que vous avez téléchargé, installé et chargé les paquets R suivants: vegan (pour analyses multivariées) labdsv (pour l’identification d’espèces indicatrices dans l’arbre de régression multivarié) MASS (pour l’analyse discriminante linéaire) mvpart* (pour les arbres de régression multivarié) ggplot2 (pour visualiser quelques résultats) # Installez les paquets requis install.packages(&quot;vegan&quot;) install.packages(&quot;labdsv&quot;) install.packages(&quot;MASS&quot;) install.packages(&quot;ggplot2&quot;) # installez mvpart de l&#39;archive install.packages(&quot;remotes&quot;) remotes::install_url(&quot;https://cran.r-project.org/src/contrib/Archive/mvpart/mvpart_1.6-2.tar.gz&quot;) *Le paquet mvpart n’est plus hébergé sur CRAN, mais est toujours disponible dans les archives. Pour installer mvpart, vous pouvez également télécharger la version .tar.gz depuis ici et aller dans l’onglet “Packages” sur le panneau inférieur droit de R Studio, et cliquer sur “Installer les paquets”. Choisissez d’installer à partir d’un fichier d’archives de paquets, et sélectionnez le fichier .tar.gz pour mvpart. # Chargez les pacquets requis library(vegan) library(labdsv) library(MASS) library(mvpart) library(ggplot2) "],["why-advanced-multivariate-methods.html", "Chapitre 3 Why “advanced multivariate methods”?", " Chapitre 3 Why “advanced multivariate methods”? L’atelier précédent a donné un premier aperçu des analyses multivariées sans contraintes: Comment choisir les mesures de distances et les transformations appropriées selon le type de données Groupement hiérarchique Ordinations sans contraintes Analyses en composantes principales Analyse en coordonnées principales Analyse de correspondances Positionnement multidimensionnel non métrique En se basant sur ces acquis, le présent atelier se concentrera sur les analyses sous contraintes. Toutes les méthodes vues lors du précédent atelier ont permis de relever des tendances dans la structure de communautés d’espèces ou des descripteurs par rapport à des sites, mais pas d’explorer comment les variables environnementales pouvaient expliquer ces tendances. Avec des analyses sous contraintes telles l’analyse canonique de redondances (RDA), l’analyse linéaire discriminante (LDA) et l’arbre de régression multivarié (MRT), il sera possible de décrire et de prédire les relations entre la structure des communautés et les variables environnementales. "],["exploration.html", "Chapitre 4 Exploration les données 4.1 Données d’abondances d’espèces 4.2 Données environnementales", " Chapitre 4 Exploration les données Encore une fois, nous utiliserons les données de la rivière Doubs. “DoubsSpe.csv” est une matrice de données d’abondance d’espèces de communautés de poissons dans laquelle la première colonne contient les noms des sites de 1 à 30 et les colonnes subséquentes correspondent aux différentes espèces de poissons. “DoubsEnv.csv” est une matrice de données environnementales pour les mêmes sites. La première colonne contient donc les noms des sites de 1 à 30 et les colonnes suivantes les mesures de 11 variables abiotiques. Notez que les données utilisées pour les analyses d’ordination sont généralement en format long (EN). Encore une fois, nous utiliserons les données de la rivière Doubs (Verneaux 1973) pour cet atelier. DoubsSpe.csv est une matrice de données d’abondance d’espèces de communautés de poissons dans laquelle la première colonne contient les noms des sites de 1 à 30 et les colonnes subséquentes correspondent à 27 différentes espèces de poissons. DoubsEnv.csv st une matrice de données environnementales pour les mêmes sites. La première colonne contient donc les noms des sites de 1 à 30 et les colonnes suivantes les mesures de 11 variables abiotiques. Notez que les données utilisées pour les analyses d’ordination sont généralement en format long (EN). # Assurez vous que les fichiers se trouvent dans votre # répertoire de travail! Si R ne trouve pas le jeu de # données, définissez votre répertoire de travail avec # setwd() au dossier dans lequel vos données sont # sauvegardées (par exemple setwd(&#39;~/Desktop/workshop10&#39;)) spe &lt;- read.csv(&quot;data/doubsspe.csv&quot;, row.names = 1) spe &lt;- spe[-8, ] # Supprimer site 8 (pas d&#39;espèces). # Matrice d&#39;abondances d&#39;espèces de poissons: “DoubsSpe.csv” spe &lt;- read.csv(&quot;data/doubsspe.csv&quot;, row.names = 1) spe &lt;- spe[-8, ] # Supprimer site 8 (pas d&#39;espèces). # Attention! Exécuter cette ligne une seule fois. # Matrice de données environnementales: “DoubsEnv.csv” env &lt;- read.csv(&quot;data/doubsenv.csv&quot;, row.names = 1) env &lt;- env[-8, ] # Supprimer le site 8 puisqu&#39;on l&#39;a supprimé de la matrice d&#39;abondance. # N&#39;exécuter qu&#39;une seule fois. 4.1 Données d’abondances d’espèces Nous pouvons utiliser les fonctions de résumé pour explorer les données “Spe” (données d’abondances de poissons) et découvrir les caractéristiques telles que les dimensions de la matrice, les noms des colonnes et les statistiques descriptives de ces colonnes. Ceci est un rappel de l’atelier 2. Pour commencer, explorons la matrice des abondances de poissons. names(spe) # noms d&#39;objets (espèces) ## [1] &quot;CHA&quot; &quot;TRU&quot; &quot;VAI&quot; &quot;LOC&quot; &quot;OMB&quot; &quot;BLA&quot; &quot;HOT&quot; &quot;TOX&quot; &quot;VAN&quot; &quot;CHE&quot; &quot;BAR&quot; &quot;SPI&quot; ## [13] &quot;GOU&quot; &quot;BRO&quot; &quot;PER&quot; &quot;BOU&quot; &quot;PSO&quot; &quot;ROT&quot; &quot;CAR&quot; &quot;TAN&quot; &quot;BCO&quot; &quot;PCH&quot; &quot;GRE&quot; &quot;GAR&quot; ## [25] &quot;BBO&quot; &quot;ABL&quot; &quot;ANG&quot; dim(spe) # dimensions de la matrice ## [1] 29 27 Et, si on veut plus de détails sur les objets de la matrice, c’est-à-dire les espèces: head(spe) # 5 premières lignes str(spe) # structure d&#39;objets de la matrice summary(spe) # statistiques descriptives des objets (min, moyenne, max, etc.) Il est également utile de jeter un coup d’œil rapide à la structure de la communauté en représentant graphiquement la distribution de l’abondance des espèces dans la matrice de communauté. # Compter la fréquence d&#39;espèces dans chaque classe # d&#39;abondance ab &lt;- table(unlist(spe)) # Visualiser cette distribution barplot(ab, las = 1, xlab = &quot;Abundance class&quot;, ylab = &quot;Frequency&quot;, col = grey(5:0/5)) Vous remarquerez peut-être qu’il y a beaucoup de zéros dans les données d’abondance. Combien y a-t-il de zéros? sum(spe == 0) ## [1] 408 Quelle proportion de l’ensemble des données cela représente-t-il ? sum(spe == 0)/(nrow(spe) * ncol(spe)) ## [1] 0.5210728 Plus de 50% de notre jeu de données est composé de zéros ! C’est un pourcentage élevé, mais pas inhabituel pour des données sur l’abondance des espèces. Cependant, de nombreux zéros peuvent entraîner un problème de double zéro, où des absences communes augmentent artificiellement la similarité entre les sites, en termes de composition de leur communauté. En d’autres termes, deux sites peuvent sembler plus similaires simplement parce qu’ils manquent tous les deux certaines espèces, même si les absences communes ne les rendent pas écologiquement similaires. Nous voulons plutôt que les présences communes déterminent la similarité des sites. Pour éviter ce problème de double zéro, nous allons appliquer une transformation aux données sur les espèces. Legendre and Gallagher (2001) a proposé cinq pré-transformations des données d’espèces, dont quatre sont disponibles dans la fonction decostand() du paquet vegan. La transformation de Hellinger exprime les abondances comme la racine carrée de leur abondance relative sur chaque site (Borcard, Gillet, and Legendre 2011), ce qui résout le problème des doubles zéros. Nous appliquerons cette transformation à l’ensemble de données sur l’abondance des poissons. # Appliquer la transformation de Hellinger pour corriger le # problème de double zéro spe.hel &lt;- decostand(spe, method = &quot;hellinger&quot;) 4.2 Données environnementales Maintenant, familiarisons-nous avec les variables environnementales abiotiques mesurées sur les mêmes sites. Tout d’abord, nous pouvons explorer la matrice en utilisant les mêmes fonctions que celles utilisées ci-dessus. names(env) ## [1] &quot;das&quot; &quot;alt&quot; &quot;pen&quot; &quot;deb&quot; &quot;pH&quot; &quot;dur&quot; &quot;pho&quot; &quot;nit&quot; &quot;amm&quot; &quot;oxy&quot; &quot;dbo&quot; dim(env) ## [1] 29 11 head(env) ## das alt pen deb pH dur pho nit amm oxy dbo ## 1 0.3 934 48.0 0.84 7.9 45 0.01 0.20 0.00 12.2 2.7 ## 2 2.2 932 3.0 1.00 8.0 40 0.02 0.20 0.10 10.3 1.9 ## 3 10.2 914 3.7 1.80 8.3 52 0.05 0.22 0.05 10.5 3.5 ## 4 18.5 854 3.2 2.53 8.0 72 0.10 0.21 0.00 11.0 1.3 ## 5 21.5 849 2.3 2.64 8.1 84 0.38 0.52 0.20 8.0 6.2 ## 6 32.4 846 3.2 2.86 7.9 60 0.20 0.15 0.00 10.2 5.3 Nous pouvons alors nous attarder un peu plus sur les objets, qui sont les variables environnementales dans ce cas. str(env) summary(env) 4.2.1 Colinéarité Il est également conseillé de vérifier les corrélations entre les variables, car les méthodes d’ordination sous contrainte que nous utiliserons sont très sensibles aux colinéarités dans la matrice explicative. Cela implique qu’une variable peut sembler très importante simplement parce qu’elle a été traitée en premier dans l’analyse si elle est fortement corrélée avec une ou plusieurs autres variables qui contribuent à expliquer la variable de réponse. # On peut également détecter (visuellement) les colinéarités entres variables: heatmap(abs(cor(env)), # corrélation de Pearson (note: ce sont des valeurs absolues!) col = rev(heat.colors(6)), Colv = NA, Rowv = NA) legend(&quot;topright&quot;, title = &quot;R de Pearson&quot;, legend = round(seq(0,1, length.out = 6),1), y.intersp = 0.7, bty = &quot;n&quot;, fill = rev(heat.colors(6))) Certaines variables semblent corrélées… Par exemple, das est fortement corrélé avec alt, deb, dur, nit, entre autres! 4.2.2 Standardisation des données Il est impossible de comparer les effets de variables qui ont des unités différentes. Par exemple, une variable mesurée en millimètres semblerait plus importante que si elle était mesurée en mètres, simplement parce que la valeur est plus grande (par exemple, 1000 millimètres contre 1 mètre). La normalisation des variables avec des unités différentes est donc cruciale. Dans ce jeu de données, les données environnementales sont toutes exprimées dans des unités différentes et devront donc être normalisées avant d’effectuer des ordinations. Nous pouvons à nouveau utiliser la fonction decostand() pour normaliser les variables environnementales. # standardiser les données env.z &lt;- decostand(env, method = &quot;standardize&quot;) # centrer les données (moyenne ~ 0) round(apply(env.z, 2, mean), 1) ## das alt pen deb pH dur pho nit amm oxy dbo ## 0 0 0 0 0 0 0 0 0 0 0 # réduire les données (écart type = 1) apply(env.z, 2, sd) ## das alt pen deb pH dur pho nit amm oxy dbo ## 1 1 1 1 1 1 1 1 1 1 1 References "],["que-sont-les-ordinations-contraintes.html", "Chapitre 5 Que sont les ordinations “contraintes” ?", " Chapitre 5 Que sont les ordinations “contraintes” ? Décrite à l’origine par Rao (1964), les analyses canoniques rassemblent de nombreuses méthodes statistiques combinant les concepts d’ordination et de régression et partageant un but commun, qui est d’identifier la relation entre un ensemble de variables réponse (matrice \\(Y\\), décrivant généralement la composition en espèces des communautés) et un ensemble de variables explicatives (matrice \\(X\\), contenant généralement des descripteurs environnementaux). Les analyses canoniques permettent aux utilisateurs de tester des hypothèses écologiques concernant les facteurs environnementaux qui déterminent la composition des communautés d’espèces. Parmi l’ensemble de méthodes d’analyses canoniques existantes, nous insisterons ici principalement sur l’analyse canonique de redondance (RDA). References "],["analyse-canonique-de-redondances.html", "Chapitre 6 Analyse canonique de redondances 6.1 Computation 6.2 Implémentation dans R 6.3 Défi 1", " Chapitre 6 Analyse canonique de redondances L’analyse de redondance (RDA) est une extension directe de la régression multiple, car elle modélise l’effet d’une matrice explicative \\(X\\) (n x p) sur une matrice de réponse \\(Y\\) (n x m). La différence ici est que nous pouvons modéliser l’effet d’une matrice explicative sur une matrice de réponse*, plutôt que sur une seule variable de réponse. Par exemple, RDA nous permet de modéliser l’effet des variables environnementales sur l’ensemble de la communauté, plutôt que sur la richesse des espèces. Pour ce faire, on effectue une ordination de \\(Y\\) pour obtenir des axes d’ordination qui sont des combinaisons linéaires des variables de \\(X\\). Figure 6.1: La structure d’une analyse de redondance (RDA). Notez que les variables explicatives dans \\(X\\) peuvent être des variables quantitatives, qualitatives ou binaires. Si elles sont quantitatives, les variables explicatives en \\(X\\) doivent être centrées, standardisées (si les variables explicatives sont dans des unités différentes), transformées (pour limiter l’asymétrie des variables explicatives) ou normalisées (pour linéariser les relations) selon les mêmes principes que dans l’ACP. La colinéarité entre les variables \\(X\\) doit également être réduite avant l’ACR. Nous avons commencé ce processus lors de l’exploration des données : nos données communautaires sont transformées par Hellinger, et nos variables environnementales sont centrées et normalisées. Cependant, nous avons encore quelques problèmes de colinéarité qui n’ont pas été résolus. Parfois, nous avons plus de variables explicatives que nécessaire pour comprendre les déterminants de notre variable de réponse. La meilleure façon de construire un modèle est toujours d’utiliser un raisonnement écologique pour déterminer quelles variables doivent être incluses ou exclues. Toutefois, s’il y a encore trop de variables incluses dans le modèle, ou si certaines d’entre elles sont fortement colinéaires, les variables explicatives peuvent être sélectionnées par une sélection progressive ou régressive qui élimine les variables explicatives non significatives. Toutefois, cette approche doit toujours être adoptée après la sélection écologique des variables, en fonction de votre compréhension du système. Nous reviendrons sur ce sujet plus tard ! 6.1 Computation L’analyse de la redondance est un processus en deux étapes (Legendre and Legendre 2012). La première étape est une régression multiple, où chaque objet de \\(Y\\) est régressé sur les variables explicatives de \\(X\\), ce qui donne une matrice de valeurs ajustées \\(Y_{fit}\\). Cette étape est calculée par l’équation linéaire suivante: \\[Y_{fit} = X[X&#39;X]^{-1}X&#39;Y\\] Dans la deuxième étape, nous appliquons une analyse en composantes principales (PCA ou ACP) sur la matrice ajustée \\(Y_{fit}\\) pour réduire la dimensionnalité, c’est-à-dire pour obtenir les valeurs propres et les vecteurs propres. On obtient alors une matrice \\(Z\\) qui contient les axes canoniques, qui correspondent à des combinaisons linéaires des variables explicatives dans l’espace de \\(X\\). La linéarité des combinaisons des variables \\(X\\) est une propriété fondamentale de la RDA. Dans l’analyse de la composition des communautés, ces axes canoniques sont interprétés comme des gradients environnementaux complexes. Figure 6.2: Le processus de computation d’une RDA, tirée de Legendre &amp; Legendre (2012). Une fois le RDA réalisé, plusieurs statistiques peuvent être calculées pour interpréter le pouvoir explicatif des variables incluses et déterminer si les relations observées sont significatives. Ces statistiques comprennent : \\(R^2\\), qui mesure la force de la relation canonique entre \\(Y\\) et \\(X\\) en calculant la proportion de la variation de \\(Y\\) expliquée par les variables de \\(X\\), Le \\(R^2\\) ajusté, qui mesure également la force de la relation entre \\(Y\\) et \\(X\\), mais applique une correction du \\(R^2\\) pour prendre en compte le nombre de variables explicatives. C’est la statistique qui doit être rapportée. La statistique F correspond à un test global de significativité d’une RDA en comparant le modèle calculé à un modèle nul. Ce test est basé sur l’hypothèse nulle selon laquelle la force de la relation calculé par le \\(R^2\\) n’est pas supérieure à la valeur qui serait obtenue pour des matrices X et Y de même taille sans aucune relation statistique. Notons que la statistique de F peut également être utilisée pour tester la significativité de chaque axe canonique de manière séquentielle. 6.2 Implémentation dans R Un RDA peut être calculée en utilisant la fonction rda() du paquet vegan, comme suit: Étape 1: Transformer et/ou standardiser les données. Nous avons déjà appliqué une transformation de Hellinger à notre matrice de communauté, et standardisé nos variables explicatives dans la section : 4. Cependant, nous avons remarqué que la variable das était colinéaire avec plusieurs autres variables. Nous allons commencer par supprimer cette variable : # On utilisera nos données explicatives standardisées Enlever # la variable &#39;distance from the source&#39; (colinéarité avec # autres variables) env.z &lt;- subset(env.z, select = -das) Étape 2: Effectuer une RDA. # Modèlise l&#39;effect de tous les variables environnementales # sur la composition en espèces des communautés spe.rda &lt;- rda(spe.hel ~ ., data = env.z) Étape 3: Extraire les résultats de la RDA. summary(spe.rda) ... ## Partitioning of variance: ## Inertia Proportion ## Total 0.5025 1.0000 ## Constrained 0.3689 0.7341 ## Unconstrained 0.1336 0.2659 ... Pour interpréter les résultats d’une RDA, on peut d’abord ce concentrer sur cette partie clé de la sortie: ... ## Partitioning of variance: ## Inertia Proportion ## Total 0.5025 1.0000 ## Constrained 0.3689 0.7341 ## Unconstrained 0.1336 0.2659 ... Constrained Proportion: variance de \\(Y\\) expliquée par \\(X\\) (73.41%) Unconstained Proportion: variance in \\(Y\\) non expliquée par (26.59%) Comment présenteriez-vous ces résultats? Les variables environnementales mesurées expliquent 73.41% de la variation dans la composition en espèces des communautés de poissons dans la rivière Doubs. Le reste du résumé de la RDA n’est pas reproduit ici, car il est long. Mis à part la section imprimée ci-dessus, le résumé contient : Valeurs propres, et leur contribution à la variance Valeurs propres contraintes cumulées, y compris la proportion cumulée de variance expliquée par chaque axe dans l’ordination RDA finale. Ces axes représentent les variables environnementales remises à l’échelle. Si vous devez sélectionner un sous-ensemble d’axes pour d’autres analyses, vous pouvez utiliser cette proportion cumulative pour sélectionner les premiers axes jusqu’à ce que vous atteigniez un seuil de votre choix. Scores pour les espèces, les sites et les variables explicatives, qui sont les coordonnées de chacun de ces objets dans l’espace RDA. La mise à l’échelle par défaut est de type 2 (nous reviendrons à ceci plus tard). 6.2.1 Sélection de variables Si nous voulons simplifier ce modèle, nous pouvons effectuer une sélection progressive (ou régressive). Ces types de sélections nous aident à sélectionner les variables qui sont statistiquement importantes. Cependant, il est important de noter que la sélection de variables avec un raisonnement écologique est beaucoup plus importante que d’effectuer une sélection de cette manière. Si une variable d’intérêt écologique n’est pas sélectionnée, cela ne signifie pas qu’elle doit être retirée du RDA. Ici, nous allons effectuer une sélection progressive sur nos 11 variables environnementales. Pour cela, nous pouvons utiliser la fonction ordiR2step() (ou utiliser la fonction forward.sel du paquet packfor): # Sélection progressive de variables: fwd.sel &lt;- ordiR2step(rda(spe.hel ~ 1, data = env.z), # modèle le plus simple scope = formula(spe.rda), # modèle &quot;complet&quot; direction = &quot;forward&quot;, R2scope = TRUE, # limité par le R2 du modèle &quot;complet&quot; pstep = 1000, trace = FALSE) # mettre TRUE pour voir le processus du sélection! Essentiellement, on ajoute une variable à la fois au modèle, et on retient la variable si elle augmente significativement le \\(R^2\\) ajusté du modèle. Quelles variables ont été sélectionnées? # Vérifier le nouveau modèle avec les variables sélectionnée fwd.sel$call ## rda(formula = spe.hel ~ alt + oxy + dbo, data = env.z) Quel est le R2 ajusté d’une RDA incluant seulement les variables significatives? # Écrire notre nouveau modèle spe.rda.signif &lt;- rda(spe.hel ~ alt + oxy + dbo, data = env.z) # vérifier son R2 ajusté RsquareAdj(spe.rda.signif) ## $r.squared ## [1] 0.5894243 ## ## $adj.r.squared ## [1] 0.5401552 Les variables explicatives (altitude, oxygène et demande biologique en oxygène) expliquent maintenant 59% de la variance de \\(Y\\) (abondance des espèces entre les sites, ou composition de la communauté). Lorsque nous corrigeons pour le nombre de variables dans \\(X\\), le \\(R^2\\) ajusté nous indique que trois variables sélectionnées expliquent 54% de la variance dans l’abondance des espèces. Comme le \\(R^2\\) ajusté est corrigé pour le nombre de variables explicatives, il est comparable entre modèles et jeux de données. Pour cette raison, il est préférable de rapporter le \\(R^2\\) ajusté lorsque vous présentez le résultat d’un RDA pour un article, ou dans une étude qui compare le pouvoir explicatif de différents modèles. 6.2.2 Tester la significativité La fonction anova.cca() nous permet de tester la significativité globale de notre RDA. anova.cca(spe.rda.signif, permutations = 1000) ... ## Df Variance F Pr(&gt;F) ## Model 3 0.29619 11.963 0.000999 *** ## Residual 25 0.20632 ## --- ... On peut aussi tester la significativité de chaque variable avec by = 'term'! anova.cca(spe.rda.signif, permutations = 1000, by = &quot;term&quot;) ... ## Model: rda(formula = spe.hel ~ alt + oxy + dbo, data = env.z) ## Df Variance F Pr(&gt;F) ## alt 1 0.164856 19.9759 0.000999 *** ## oxy 1 0.082426 9.9877 0.000999 *** ## dbo 1 0.048909 5.9264 0.002997 ** ## Residual 25 0.206319 ... On peut également tester la significativité de chaque axe canonique avec by = \"axis\". Rappelez-vous que ces axes représentent la variation des variables explicatives en moins de dimensions. anova.cca(spe.rda.signif, step = 1000, by = &quot;axis&quot;) ... ## Model: rda(formula = spe.hel ~ alt + oxy + dbo, data = env.z) ## Df Variance F Pr(&gt;F) ## RDA1 1 0.218022 26.4181 0.001 *** ## RDA2 1 0.050879 6.1651 0.001 *** ## RDA3 1 0.027291 3.3069 0.004 ** ## Residual 25 0.206319 ... Notre modèle complet est statistiquement significatif (p = 0.001), et chaque variable incluse dans ce modèle est également significative (p = 0.001). Chaque axe canonique résultant du RDA est également statistiquement significatif (p = 0.001). 6.2.3 Représentation graphique des RDAs L’un des aspects les plus puissants de RDA est la visualisation simultanée de votre réponse et des variables explicatives (c’est-à-dire les espèces et les variables environnementales). Comme pour la PCA dans l’atelier 9, on doit choisir entre deux options de cadrage: Type 1 Type 2 distances entre objects ≈ distances euclidiennes angles entre variables ≈ leur corrélation # Type 1 scaling ordiplot(spe.rda.signif, scaling = 1, type = &quot;text&quot;) # Type 2 scaling ordiplot(spe.rda.signif, scaling = 2, type = &quot;text&quot;) Scaling 1 permet d’interpréter les distances entre objets dans la matrice réponse. Les communautés dans les sites (chiffres) plus rapprochés ont des compositions plus similaires. Les espèces plus rapprochés occupent souvent les mêmes sites. Scaling 2 montre les effets des variables explicatives. Longues flèches = cette variable explique fortement la variation dans la matrice d’abondances. Flèches pointant des directions opposées montrent une relation négative. Flèches pointant la même direction montrent une relation positive. 6.2.3.1 Configuration des triplots RDA Les fonctions plot() et ordiplot() produisent des triplots rapidement et facilement, mais on peut aussi configurer les graphiques avec l’extraction de scores avec scores() et leur visualisation avec points(), text(), et arrows(). Voici un exemple de triplot personnalisé. N’hésitez pas à jouer avec les couleurs et d’autres paramètres pour vous approprier cet exemple! # Configuration des triplots RDA! ## extrait le % expliqué par les 2 premiers axes perc &lt;- round(100*(summary(spe.rda.signif)$cont$importance[2, 1:2]), 2) ## scores - ceux-ci sont des coordonnées dans l&#39;espace RDA sc_si &lt;- scores(spe.rda.signif, display=&quot;sites&quot;, choices=c(1,2), scaling=1) sc_sp &lt;- scores(spe.rda.signif, display=&quot;species&quot;, choices=c(1,2), scaling=1) sc_bp &lt;- scores(spe.rda.signif, display=&quot;bp&quot;, choices=c(1, 2), scaling=1) ## Configuration du graphique # Commencer avec un graphique vide avec le cadrage, les axes, et des titres plot(spe.rda.signif, scaling = 1, # type de cadrage type = &quot;none&quot;, # garder le graphique vide pour l&#39;instant frame = FALSE, # fixer les limites des axes xlim = c(-1,1), ylim = c(-1,1), # ajouter des titres au graphique et aux axes main = &quot;Triplot RDA - cadrage 1&quot;, xlab = paste0(&quot;RDA1 (&quot;, perc[1], &quot;%)&quot;), ylab = paste0(&quot;RDA2 (&quot;, perc[2], &quot;%)&quot;) ) # ajouter des points pour les scores des sites points(sc_si, pch = 21, # fixer le symbole (ici, un cercle rempli avec une couleur) col = &quot;black&quot;, # couleur de la bordure du cercle bg = &quot;steelblue&quot;, # couleur pour remplir le cercle cex = 1.2) # taille du cercle # ajouter des points pour les scores des espèces points(sc_sp, pch = 22, # fixer le symbole (ici, un carré rempli avec une couleur) col = &quot;black&quot;, bg = &quot;#f2bd33&quot;, cex = 1.2) # ajouter du texte pour identifier les espèces text(sc_sp + c(0.03, 0.09), # ajuster les coordonnées pour éviter des chevauchements labels = rownames(sc_sp), col = &quot;grey40&quot;, font = 2, # gras cex = 0.6) # ajouter des flèches pour les effets des variables explicatives arrows(0,0, # chaque flèche commence à (0,0) sc_bp[,1], sc_bp[,2], # et finit au score de la variable col = &quot;red&quot;, lwd = 3) # ajouter du texte pour identifier les variables explicatives text(x = sc_bp[,1] -0.1, # ajuster les coordonnées pour éviter des chevauchements y = sc_bp[,2] - 0.03, labels = rownames(sc_bp), col = &quot;red&quot;, cex = 1, font = 2) 6.3 Défi 1 Effectuer une RDA pour modèliser les effect des variables environnementales sur l’abondance des espèces d’acariens. Le jeu de données mite fait partie du paquet vegan, alors ce n’est pas nécessaire de le sauvegarder comme .csv dans votre répertoire de travail. Pour commencer, chargez les données: # Charger les données d&#39;abondance des espèces d&#39;acariens data(&quot;mite&quot;) # Charger les données environnementales data(&quot;mite.env&quot;) Rappel de fonctions utiles: decostand() rda() ordiR2step() anova.cca() ordiplot() 6.3.1 Défi 1: Solution Étape 1: Transformer et standardiser les données. # Transformer les données d&#39;abondances mite.spe.hel &lt;- decostand(mite, method = &quot;hellinger&quot;) # Standardiser les données environmentales quantiatives mite.env$SubsDens &lt;- decostand(mite.env$SubsDens, method = &quot;standardize&quot;) mite.env$WatrCont &lt;- decostand(mite.env$WatrCont, method = &quot;standardize&quot;) Étape 2: Sélectionner les variables environnementales. # RDA avec tous les variables environnementales mite.spe.rda &lt;- rda(mite.spe.hel ~ ., data = mite.env) # Sélection progressive des variables environnementales # significatives fwd.sel &lt;- ordiR2step(rda(mite.spe.hel ~ 1, data = mite.env), scope = formula(mite.spe.rda), direction = &quot;forward&quot;, R2scope = TRUE, pstep = 1000, trace = FALSE) fwd.sel$call ## rda(formula = mite.spe.hel ~ WatrCont + Shrub + Substrate + Topo, ## data = mite.env) Étape 3: Effectuer l’RDA et extraire le \\(R^2\\) ajusté. # Refaire la RDA avec seulement les variables significatives mite.spe.rda.signif &lt;- rda(mite.spe.hel ~ WatrCont + Shrub + Substrate + Topo + SubsDens, data = mite.env) # Calculer le R2 ajusté RsquareAdj(mite.spe.rda.signif)$adj.r.squared ## [1] 0.4367038 Étape 4: Tester la significativité globale du modèle. anova.cca(mite.spe.rda.signif, step = 1000) ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(formula = mite.spe.hel ~ WatrCont + Shrub + Substrate + Topo + SubsDens, data = mite.env) ## Df Variance F Pr(&gt;F) ## Model 11 0.20759 5.863 0.001 *** ## Residual 58 0.18669 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Nous trouvons que quatre variables explicatives sont retenues après la sélection progressive: WatrCont, Shrub, Substrate, et Topo. Les variables environnementales sélectionnées expliquent 43.7% (p = 0.001) de la variation dans la composition de communautés des acariens. Étape 5: Visualiser le modèle à l’aide d’un triplot! # Cadrage 1 ordiplot(mite.spe.rda.signif, scaling = 1, main = &quot;Cadrage 1&quot;) # Cadrage 2 ordiplot(mite.spe.rda.signif, scaling = 2, main = &quot;Cadrage 2&quot;) L’échelle 1 montre les similarités entre les objets de la matrice de réponses. Les sites (cercles noirs) sont globalement similaires. Quelques espèces (rouge +) se démarquent du groupe, ce qui signifie qu’elles n’occupent pas beaucoup de sites en commun avec d’autres espèces. Ces espèces pourraient donc être rares ou uniques d’un point de vue écologique. La mise à l’échelle 2 montre les effets des variables explicatives. La densité du substrat et la teneur en eau ont des flèches longues, et donc des effets forts. La présence d’arbustes (Shrub) a un effet opposé à WatrCont et SubsDens, car les flèches des arbustes sont dans des directions opposées à ces variables. Les sites varient beaucoup en termes de SubsDens, et moins en termes de WatrCont. References "],["rda-partielle.html", "Chapitre 7 RDA partielle 7.1 Exemple: RDA partielle sur les données Doubs 7.2 Défi 2", " Chapitre 7 RDA partielle La RDA partielle est un cas particulier de la RDA qui permet de tenir compte de covariables. En d’autres mots, on peut modéliser les effets linéaires de la matrice \\(X\\) sur la matrice \\(Y\\), tout en controllant pour l’effet d’une matrice de variables explicatives supplémentaires \\(W\\), appelées covariables (ou covariables). Comme dans la régression linéaire partielle, l’effet linéaire des variables \\(X\\) sur les variables \\(Y\\) est ajusté pour les effets des covariables \\(W\\). Pour cela, on effectue d’abord une RDA des covariables \\(W\\) sur les variables de réponse \\(Y\\). On extrait ensuite les résidus de ce RDA, c’est-à-dire une matrice \\(Y_{res}|W\\) contenant les variables réponses \\(Y\\) dans lesquelles l’effet de \\(W\\) a été retiré. La RDA partielle correspond à la RDA de \\(X\\) sur \\(Y_{res}|W\\). Toutes les statistiques présentées précédemment pour la RDA s’appliquent également à la RDA partielle. Figure 7.1: The basic structure of a redundancy analysis (RDA). La RDA partielle a plusieurs applications. C’est un outil puissant pour évaluer l’effet des variables environnementales sur la composition des espèces tout en tenant compte de la variation due à d’autres variables environnementales qui ne sont pas visées par l’étude. Un exemple courant de ceci en écologie des communautés est de tester l’importance des variables environnementales tout en contrôlant pour l’effet de l’espace. La RDA partielle peut également être utilisée pour contrôler des effets linéaires bien connus, ou pour isoler l’effet d’une seule variable explicative. 7.1 Exemple: RDA partielle sur les données Doubs Dans R, on peut faire une RDA partielle avec la fonction rda(). Par exemple, évaluons l’effet de la chimie de l’eau sur l’abondance des poissons (spe.hel) en tenant compte de covariables topographiques. # Divisez le tableau de données environnementales en deux: # variables topographiques et chimiques env.topo &lt;- subset(env.z, select = c(alt, pen, deb)) env.chem &lt;- subset(env.z, select = c(pH, dur, pho, nit, amm, oxy, dbo)) # Faire la RDA partielle spe.partial.rda &lt;- rda(spe.hel, env.chem, env.topo) Note: On peut aussi utiliser une syntaxe de formule comme Y ~ X + Condition(W), où Condition() permet de tenir compete de covariables. # Syntaxe alternative spe.partial.rda &lt;- rda(spe.hel ~ pH + dur + pho + nit + amm + oxy + dbo + Condition(alt + pen + deb), # covariables ici data = env.z) 7.1.1 Interprétation de la sortie d’une RDA partielle Le résultat d’une RDA partielle est très similaire à celui présenté dans la section précédente sur la RDA. La principale différence est que nous avons des covariables dans notre modèle, ce qui signifie que nous pouvons déterminer la proportion de la variation expliquée par ces variables supplémentaires, mais qui ne sont pas “intéressantes”. Encore une fois, la première section du résumé contient les éléments dont nous avons besoin pour vérifier la performance de notre RDA partielle. summary(spe.partial.rda) ... ## Partitioning of variance: ## Inertia Proportion ## Total 0.5025 1.0000 ## Conditioned 0.2087 0.4153 ## Constrained 0.1602 0.3189 ## Unconstrained 0.1336 0.2659 ... Conditioned Proportion: variance de \\(Y\\) expliquée par \\(W\\) (41.53%) Constrained Proportion: variance de \\(Y\\) expliquée par \\(X\\) (31.89%) Unconstained Proportion: variance de \\(Y\\) non expliquée (26.59%) Comment présenteriez-vous ces résultats? La chimie de l’eau explique 31.89% de l’abondance des espèces de poissons, tandis que la topographie explique 41.53% de la variation en abondances des poissons. 7.1.2 Tester la significativité Comme pour le RDA, nous pouvons interpréter la signification de notre modèle à l’aide de deux informations clés. Quel est le pouvoir explicatif du modèle ? # Extraire le R2 ajusté du modèle RsquareAdj(spe.partial.rda)$adj.r.squared ## [1] 0.2413464 Est-ce que le modèle est significatif? # Évaluer la significativité statistique du modèle anova.cca(spe.partial.rda, step = 1000) ... ## Permutation test for rda under reduced model ## Number of permutations: 999 ## ## Model: rda(X = spe.hel, Y = env.chem, Z = env.topo) ## Df Variance F Pr(&gt;F) ## Model 7 0.16024 3.0842 0.001 *** ## Residual 18 0.13360 ... Notre modèle explique 24.1% de la variation en abondance de poissons entre sites. Il est aussi statistiquement significatif (p = 0.001)! 7.1.3 Représentation graphique On peut visualiser les effets des variables environnementales sur la communauté de poissons avec la fonction ordiplot(). ordiplot(spe.partial.rda, scaling = 2, main = &quot;Rivière Doubs - Cadrage 2&quot;) Recall: Le cadrage de type 2 montre les effets des variables explicatives, donc de la matrice X sur la matrice Y une fois qu’on a controllé pour l’effet des covariables W. Note: Les variables topographiques ne sont pas représentées. Pourquoi? Le RDA partiel ne fait qu’ajuster les effets des variables explicatives en fonction des covariables. Les covariables ne sont pas d’intérêt, et ne sont donc pas représentées graphiquement. 7.2 Défi 2 Effectuez une RDA partielle de l’abondance des espèces de mites (mite.spe.hel) en fonction des variables environnementales, tenant compte de l’effet du substrat (SubsDens, WaterCont and Substrate). * Quel pourcentage de variance est expliqué par les variables environnementales? * Le modèle est-il significatif? * Quels sont les axes significatifs? Rappel des données et fonctions utiles: rda() summary() RsquareAdj() anova.cca() # voir l&#39;argument &#39;by&#39; dans ?anova.cca 7.2.1 Défi 2: Solution Étape 1: Transformer et standardiser les données. Nos données sont déjà transformés et standardisés! Étape 2: Faire la RDA partielle: mite.spe.subs &lt;- rda(mite.spe.hel ~ Shrub + Topo + Condition(SubsDens + WatrCont + Substrate), data = mite.env) # Extraire les résultats summary(mite.spe.subs) ... ## Partitioning of variance: ## Inertia Proportion ## Total 0.39428 1.00000 ## Conditioned 0.16891 0.42839 ## Constrained 0.03868 0.09811 ## Unconstrained 0.18669 0.47350 ... Shrub et Topo expliquent 9.8% de la variation de l’abondance de mites, tandis que le substrat explique 42.8% de cette variation. Étape 3: Interpréter les résultats! Quel pourcentage de variance est expliqué par les variables environnementales? RsquareAdj(mite.spe.subs)$adj.r.squared ## [1] 0.08327533 Le modèle est-il significatif? anova.cca(mite.spe.subs, step = 1000) ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(formula = mite.spe.hel ~ Shrub + Topo + Condition(SubsDens + WatrCont + Substrate), data = mite.env) ## Df Variance F Pr(&gt;F) ## Model 3 0.038683 4.006 0.001 *** ## Residual 58 0.186688 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Quels axes sont significatifs? anova.cca(mite.spe.subs, step = 1000, by = &quot;axis&quot;) ## Permutation test for rda under reduced model ## Forward tests for axes ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(formula = mite.spe.hel ~ Shrub + Topo + Condition(SubsDens + WatrCont + Substrate), data = mite.env) ## Df Variance F Pr(&gt;F) ## RDA1 1 0.027236 8.4618 0.001 *** ## RDA2 1 0.008254 2.5643 0.020 * ## RDA3 1 0.003193 0.9919 0.406 ## Residual 58 0.186688 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Le \\(R^2\\) ajusté de la RDA globale est 8.33%, et est significatif (p = 0.001). Les variables environnementales expliquent 9.81% de la variance de la composition des espèces d’acariens entre les sites, tandis que les covariables du substrat expliquent 42.84% de cette variation. Cependant, 47.35% de la variation reste inexpliquée. Les deux premiers axes canoniques sont significatifs. "],["partitionnement-de-la-variation.html", "Chapitre 8 Partitionnement de la variation 8.1 Partitionnement de la variation dans R 8.2 Tester la significativité 8.3 Défi 3", " Chapitre 8 Partitionnement de la variation Le partitionnement de la variation est un type d’analyse qui combine à la fois la RDA et la RDA partielle pour diviser la variation d’une matrice de variable réponse en deux, trois ou quatre jeux de données explicatives. Par exemple, on pourrait partitionner la variation dans une matrice de communauté en fonctiond e variables abiotiques et biotiques, ou de variables locales et à large échelle. Figure 8.1: La structure d’un partitionnement de la variation. Le résultat d’un partitionnement de la variation est généralement représenté par un diagramme de Venn sur lequel sont annotés les pourcentages de variance expliquée par chacun des jeux de données explicatives. Dans le cas où on partionnerait la variation entre deux matrices explicatives, le résultat pourrait être représenté comme suit: Figure 8.2: Représentation des résultats d’un partitionnement de la variation. Ici, les fraction représentent: La fraction \\([a + b + c]\\) est la variance expliquée par \\(X1\\) et* \\(X2\\) ensemble, calculée à partir d’une RDA de \\(Y\\) par \\(X1 + X2\\). La fraction \\([d]\\) est la variance inexpliquée par \\(X1\\) et* \\(X2\\) ensemble, obtenue à partir de la même RDA que ci-dessus. La fraction \\([a]\\) est la variance expliquée par \\(X1\\) seulement, calculée en faisant une RDA partielle de \\(Y\\) par \\(X1 | X2\\) (en contrôlant pour \\(X2\\)). La fraction \\([c]\\) est la variance expliquée par \\(X2\\) seulement, calculée en faisant une RDA partielle de \\(Y\\) par \\(X2 | X1\\) (en contrôlant pour \\(X1\\)). La fraction \\([b]\\) est calculée par soustraction, c’est-à-dire \\(b = [a + b] + [b + c] - [a + b + c].\\) Comme \\([b]\\) n’est pas le résultat d’une RDA, il est impossible de tester sa significativité. Elle peut également être négative, ce qui indique que la matrice de réponse est mieux expliquée par la combinaison de \\(X1\\) et \\(X2\\) que par l’une ou l’autre des matrices prise individuellement. 8.1 Partitionnement de la variation dans R Pour démontrer comment le partitionnement des variations fonctionne dans R, nous allons partitionner la variation de la composition des espèces de poissons entre les variables chimiques et topographiques. La fonction varpart() de vegan nous facilite la tâche. # Partitionner la variation de la composition des espèces de # poissons spe.part.all &lt;- varpart(spe.hel, env.chem, env.topo) spe.part.all$part # access results! ## No. of explanatory tables: 2 ## Total variation (SS): 14.07 ## Variance: 0.50251 ## No. of observations: 29 ## ## Partition table: ## Df R.squared Adj.R.squared Testable ## [a+b] = X1 7 0.60579 0.47439 TRUE ## [b+c] = X2 3 0.41526 0.34509 TRUE ## [a+b+c] = X1+X2 10 0.73414 0.58644 TRUE ## Individual fractions ## [a] = X1|X2 7 0.24135 TRUE ## [b] 0 0.23304 FALSE ## [c] = X2|X1 3 0.11205 TRUE ## [d] = Residuals 0.41356 FALSE ## --- ## Use function &#39;rda&#39; to test significance of fractions of interest On peut ensuite visualiser les résultats avec la fonction plot(). # Visualiser les résultats avec un diagramme Venn plot(spe.part.all, Xnames = c(&quot;Chem&quot;, &quot;Topo&quot;), # noms des matrices explicatives bg = c(&quot;seagreen3&quot;, &quot;mediumpurple&quot;), alpha = 80, digits = 2, cex = 1.5) Les variables chimiques expliquent 24.1% de la variation de la composition des espèces de poissons, les variables topographiques expliquent 11.2% de la variation de la composition des espèces de poissons, et ces deux groupes de variables conjointement expliquent 23.3% de la variation de la composition des espèces de poissons. Soyez prudent lorsque vous rapportez les résultats du partitionnement de la variation ! La fraction partagée [b] ne représente pas un effet d’interaction des deux matrices explicatives. Considérez-la comme un chevauchement entre \\(X1\\) et \\(X2\\). Elle représente la fraction partagée de la variation expliquée lorsque les deux sont incluses dans le modèle, c’est-à-dire la partie de la variation qui ne peut être attribuée à \\(X1\\) ou \\(X2\\) séparément. En d’autres termes, le partitionnement de la variation ne peut pas démêler les effets de la chimie et de la topographie pour 23.3% de la variation de la composition de la communauté de poissons. 8.2 Tester la significativité La sortie de la fonction varpart() rapporte le \\(R^2\\) ajusté pour chaque fraction, mais vous remarquerez que le tableau n’inclut aucun test de signification statistique. Cependant, la colonne Testable identifie les fractions qui peuvent être testées pour leur signification en utilisant la fonction anova.cca(), tout comme nous l’avons fait avec le RDA ! X1 [a+b]: Chimie sans tenir compte de topographie # [a+b] Chimie sans tenir compte de topographie anova.cca(rda(spe.hel, env.chem)) ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(X = spe.hel, Y = env.chem) ## Df Variance F Pr(&gt;F) ## Model 7 0.30442 4.6102 0.001 *** ## Residual 21 0.19809 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 X2 [b+c] Topographie sans tenir compte de chimie # [b+c] Topographie sans tenir compte de chimie anova.cca(rda(spe.hel, env.topo)) ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(X = spe.hel, Y = env.topo) ## Df Variance F Pr(&gt;F) ## Model 3 0.20867 5.918 0.001 *** ## Residual 25 0.29384 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 X1 | X2 [a] Chimie seulement (ajusté pour tenir compte de topographie) # [a] Chimie seulement anova.cca(rda(spe.hel, env.chem, env.topo)) ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(X = spe.hel, Y = env.chem, Z = env.topo) ## Df Variance F Pr(&gt;F) ## Model 7 0.16024 3.0842 0.001 *** ## Residual 18 0.13360 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 C’est une RDA partielle! X2 | X1 [c] Topographie (ajusté pour tenir compte de chimie) # [c] Topographie seulement anova.cca(rda(spe.hel, env.chem, env.topo)) ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(X = spe.hel, Y = env.chem, Z = env.topo) ## Df Variance F Pr(&gt;F) ## Model 7 0.16024 3.0842 0.001 *** ## Residual 18 0.13360 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Toutes les fractions testables dans le partitionnement de la variation sont statistiquement significatives! 8.3 Défi 3 Partitionnez la variation de l’abondance des espèces de mites entres des variables de substrat (SubsDens, WatrCont) et des variables spatiales significatives. Quelle est la proportion de variance expliquée par le substrat? par l’espace? Quelles sont les fractions significatives? Diagramme Venn des résultats! Chargez les variables spatiales: data(&quot;mite.pcnm&quot;) Rappel de fonctions utiles: ordiR2step() varpart() anova.cca(rda()) plot() 8.3.1 Défi 3: Solution Étape 1: Sélection de variables spatiales significatives. Il y a beaucoup de variables spatiales dans ce jeu de données (22 !). Nous devrions sélectionner les plus importantes, pour éviter de surcharger le modèle. # Modèle RDA avec tous les variables spatiales full.spat &lt;- rda(mite.spe.hel ~ ., data = mite.pcnm) # Sélection progressive des variables spatiales spat.sel &lt;- ordiR2step(rda(mite.spe.hel ~ 1, data = mite.pcnm), scope = formula(full.spat), R2scope = RsquareAdj(full.spat)$adj.r.squared, direction = &quot;forward&quot;, trace = FALSE) spat.sel$call ## rda(formula = mite.spe.hel ~ V2 + V3 + V8 + V1 + V6 + V4 + V9 + ## V16 + V7 + V20, data = mite.pcnm) Étape 2: Créer sous-groupes de variables explicatives. # Variables de substrat mite.subs &lt;- subset(mite.env, select = c(SubsDens, WatrCont)) # Variables spatiales significatives mite.spat &lt;- subset(mite.pcnm, select = names(spat.sel$terminfo$ordered)) # pour rapidement accèder aux variables sélectionnées Étape 3: Partitionnement de la variation dans la matrice d’abondances. mite.part &lt;- varpart(mite.spe.hel, mite.subs, mite.spat) mite.part$part$indfract # extraire résultats ## Df R.squared Adj.R.squared Testable ## [a] = X1|X2 2 NA 0.05901929 TRUE ## [b] 0 NA 0.24765221 FALSE ## [c] = X2|X1 10 NA 0.19415929 TRUE ## [d] = Residuals NA NA 0.49916921 FALSE Quelle est la proportion de variance expliquée par le substrat? 5.9% Quelle est la proportion de variance expliquée par l’espace? 19.4% Étape 4: Quelles sont les fractions significatives? [a]: Substrat seulement anova.cca(rda(mite.spe.hel, mite.subs, mite.spat)) ... ## Model: rda(X = mite.spe.hel, Y = mite.subs, Z = mite.spat) ## Df Variance F Pr(&gt;F) ## Model 2 0.025602 4.4879 0.001 *** ## Residual 57 0.162583 ... [c]: Espace seulement anova.cca(rda(mite.spe.hel, mite.spat, mite.subs)) ... ## Model: rda(X = mite.spe.hel, Y = mite.spat, Z = mite.subs) ## Df Variance F Pr(&gt;F) ## Model 10 0.10286 3.6061 0.001 *** ## Residual 57 0.16258 ... Étape 5: Visualiser les résultats avec un diagramme Venn. plot(mite.part, digits = 2, Xnames = c(&quot;Subs&quot;, &quot;Space&quot;), # titre des fractions cex = 1.5, bg = c(&quot;seagreen3&quot;, &quot;mediumpurple&quot;), # ajoutez des couleurs! alpha = 80) Alors, quels sont les effets de substrat et de l’espace sur les abondances d’espèces de mites? Indice: Pourquoi on trouve un effet si important de l’espace? L’espace explique la plupart de la variation dans la communauté: elle explique 19.4% (p = 0.001) de la variation seule, et 24.8% est expliqué conjointement par l’espace et le substrat. Le susbtrat n’explique que ~6% (p = 0.001) de la variation entre sites sans l’effet de l’espace. Notez également que la moitié de la variation n’est pas expliquée par les variables que nous avons incluses dans le modèle (regardez les résidus !), le modèle pourrait donc être amélioré. Cet effet élevé de l’espace pourrait être un signe qu’un processus écologique spatial est important ici (comme la dispersion, par exemple). *Cependant, il pourrait aussi nous indiquer que nous manquons une variable environnementale importante dans notre modèle, qui varie elle-même dans l’espace! "],["arbre-de-régression-multivarié.html", "Chapitre 9 Arbre de régression multivarié 9.1 Computation 9.2 MRT dans R 9.3 Défi 4", " Chapitre 9 Arbre de régression multivarié L’arbre de régression multivarié (MRT) est une technique de groupement hiérarchique. Introduit par De’ath (2002), le MRT divise une matrice de réponse (\\(Y\\)) en groupes en fonction de seuils de variables explicatives (\\(X\\)). Comme la RDA, la MRT est une technique de régression. Alors que la première explique la structure globale des relations par un modèle linéaire, la seconde produit un modèle en arbre pour mettre en évidence les structures locales et les interactions entre les variables. Figure 9.1: The basic structure of a multivariate regression tree (MRT). L’arbre de régression multivarié a plusieurs charéctéristiques avantageux: Les résultats sont faciles à visualiser et à interpréter (c’est un arbre !) ; Il identifie clairement l’importance des variables explicatives ; Il est robuste aux valeurs manquantes ; Il est robuste à la colinéarité entre les variables explicatives ; Il peut traiter des variables explicatives brutes, alors il n’est pas nécessaire de les standardiser. Une petite note sur le vocabulaire lié aux MRTs: Branches: Chaque lignée formée par un noeud; Noeuds: Point où les données se divisent en 2 groupes (caractérisé par une valeur seuil d’une variable explicative); Feuilles: Groupe terminal de sites. 9.1 Computation Le MRT divise les données en groupes ayant des compositions en espèce semblables et caractérisés par des variables environnementales. La méthode implique deux volets s’effectuant en parallèle: 1) la construction de l’arbre et 2) la sélection de la partition finale optimale par validation croisée. The MRT splits the data into clusters of samples similar in their species composition based on environmental value thresholds. It involves two procedures running at the same time: 1) the computation of the constrained partitioning of the data, and 2) the calculation of the relative error of the successive partitioning levels by multiple cross-validations. Cette validation croisée vise, en fait, à identifier le meilleur arbre prédictif. Le “meilleur” arbre varie en fonction des objectifs de votre étude. En général, on cherche un arbre qui est parcimonieux, mais qui possède un nombre de groupes informatif. Il s’agit, bien entendu, d’une décision subjective à prendre en fonction de la question à laquelle vous tentez de répondre. 9.1.1 Construction de l’arbre: Partitionnement des données sous contrainte Premièrement, la méthode calcule toutes les partitions des sites en deux groupes. Pour chaque variable environnementale quantitative, les sites seront classés en ordre croissant des valeurs; pour chaque variable qualitative (ou catégorique), les sites seront classés par niveaux. La méthode divise les données après le premier objet, après le second, et ainsi de suite et calcule à chaque fois la somme des carrés des écarts intra-groupes de la matrice réponse. La méthode choisira la partition qui minimisera la somme des carrés des écarts intra-groupes et le point de division défini par une valeur seuil d’une variable environnementale. Ces étapes seront répétées dans les deux groupes formés précédemment, jusqu’à ce que tous les objets forment leur propre groupe. En d’autre mots, jusqu’à ce que chaque feuille de l’arbre de contienne qu’un seul objet. 9.1.2 Sélection de l’arbre: Validation croisée et élagage de l’arbre La fonction effectue également une validation croisée et identifie l’arbre ayant le meilleur pouvoir prédictif. La validation croisée s’effectue en utilisant une partie des données pour construire l’arbre et le reste des données est classé dans les groupes créés. Dans un arbre ayant un bon pouvoir prédictif, les objets sont assignés aux groupes appropriés. L’erreur relative de validation croisée (ERVC ou CVRE) mesure l’erreur de prédiction. Sans validation croisée, le nombre de partitions retenu serait celui minimisant la variance non expliquée par l’arbre (i.e. l’erreur relative: la somme des carrés des écarts intra-groupes de toutes les feuilles divisée par la somme de carrée des écarts de toutes les données). Cette solution maximise le \\(R^2\\) et on obtiendrait donc un arbre explicatif plutôt que prédictif. 9.2 MRT dans R La fonction mvpart() du paquet mvpart calcule à la fois la partition et les étapes de validation croisée requises pour construire un arbre de régression multivarié. Nous allons démontrer le processus de construction d’un arbre de régression multivarié sur les données de la rivière Doubs. # Enlever la variable “distance from source” env &lt;- subset(env, select = -das) # Construire l&#39;arbre de regression multivarié doubs.mrt &lt;- mvpart(as.matrix(spe.hel) ~ ., data = env, xv = &quot;pick&quot;, # selection graphique intéractive xval = nrow(spe.hel), # nombre de validations xvmult = 100, # nombre de validations multiples which = 4, # identifier les noeuds legend = FALSE, margin = 0.01, cp = 0) ## X-Val rep : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ## Minimum tree sizes ## tabmins ## 2 3 4 6 7 8 9 10 ## 8 1 5 6 16 32 1 31 À ce stade, vous devrez sélectionner l’arbre avec un nombre approprié de groupes, en fonction de l’objectif de votre étude. En d’autres mots, vous devez élaguer l’arbre en choisissant l’arbre le plus approprié. Un arbre entièrement résolu n’est pas le résultat souhaitable ; au contraire, on s’intéresse généralement à un arbre comprenant uniquement des partitions/groupes informatifs. Dans ce cas, il est possible d’avoir une idée a priori du nombre de groupes potentiels à retenir. Vous pouvez faire ce choix de manière interactive, avec l’argument xv = \"pick\". Le graphique montre l’erreur relative (RE, en vert) et l’erreur relative de validation croisée (en bleu) d’arbres de tailles croissantes. Le point rouge indique la solution avec la valeur minimale de CVRE et le point orange montre l’arbre le plus petit dont la valeur de CVRE est à 1 écart type de de la valeur CVRE minimale. Breiman et al. (1984) suggèrent de choisir cette dernière option car cet arbre a à la fois une erreur relative de validation croisée près de la plus faible et il contient un nombre restreint de groupe, ce qui en fait un choix parcimonieux. Les barres vertes en haut du graphique indiquent le nombre de fois que chaque taille d’arbre a été choisi durant le processus de validation croisée. Ce graphique est interactif. Il faudra donc cliquer sur le point bleu correspondant à la taille de l’arbre choisie. En résumé: Points verts: Erreur relative Points bleus: Erreur relative de validation croisée (CVRE) Point rouge: Arbre avec la valeur minimale de CVRE Point orange: l’arbre le plus petit ayant un CVRE à 1 écart type du CVRE minimal Barres vertes: # de fois que chaque taille d’arbre a été choisi Nous n’avons pas de prédiction a priori sur la façon de diviser ces données, donc nous allons sélectionner le plus petit arbre à moins d’une erreur standard de l’arbre qui est le mieux ajusté (c’est-à-dire, le point orange). Nous pouvons sélectionner cet arbre en utilisant l’argument xv = \"1se\". # Faire le choix d&#39;arbre (point orange) doubs.mrt &lt;- mvpart(as.matrix(spe.hel) ~ ., data = env, xv = &quot;1se&quot;, # select smallest tree within 1 se xval = nrow(spe.hel), # number of cross-validations xvmult = 100, # number of multiple cross-validations which = 4, # plot both node labels legend = FALSE, margin = 0.01, cp = 0) ## X-Val rep : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 ## Minimum tree sizes ## tabmins ## 2 5 6 7 8 9 10 ## 6 1 9 11 29 5 39 Des statistiques sont affichées au bas de l’arbre: l’erreur résiduelle, l’erreur de validation croisée et l’erreur type. Cet arbre n’est constitué que de deux branches séparées par un noeud. Sous chaque feuille, on retrouve un petit diagramme à bandes montrant les abondances des espèces des sites retrouvés dans la branche, le nombre de sites et l’erreur relative. De cette figure, on peut rapporter les statistiques suivantes: * La matrice des espèces est partitionnée en fonction d’un seuil d’altitude (361.5 m) * Erreur résiduelle = 0.563, ce qui signifie que le R2 du modèle est 43.7% (\\(1 - 0.563 = 0.437\\)) 9.2.1 Processus de sélection On peut aussi comparer plusieurs solutions, pour nous aider à choisir le meilleur arbre. Par exemple, examinons une solution à dix groupes! # Solution avec 10 groupes mvpart(as.matrix(spe.hel) ~ ., data = env, xv = &quot;none&quot;, # aucune validation croisée size = 10, # fixer la taille de l&#39;arbre which = 4, legend = FALSE, margin = 0.01, cp = 0, prn = FALSE) Cet arbre est beaucoup plus difficile à interpréter, car il y a beaucoup de groupes ! Bien que cette version de l’arbre offre un pouvoir explicatif plus élevé, son pouvoir prédictif (erreur CV = 0.671) est sensiblement le même que celui de la solution précédente à deux groupes (erreur CV = 0.673). Ceci suggère que nous pourrions essayer un arbre avec un peu plus de groupements que la solution à deux groupes, tout en restant en dessous de dix groupes. Voyons une solution avec moins de groupes (4 groupes)! # Solution avec 4 groupes seulement mvpart(as.matrix(spe.hel) ~ ., data = env, xv = &quot;none&quot;, # aucune validation croisée size = 4, # fixer la taille de l&#39;arbre which = 4, legend = FALSE, margin = 0.01, cp = 0, prn = FALSE) Cet arbre est beaucoup plus facile à interpréter! Il offre également un pouvoir explicatif plus élevé (erreur plus faible) que notre solution originale, et un pouvoir prédictif plus élevé que les deux solutions précédentes (erreur CV). Nous avons un champion! 9.2.2 Interprétation des résultats Pour savoir combien de variance est expliquée par chaque nœud de l’arbre, nous devons consulter le paramètre de complexité (CP). Le CP à nsplit = 0 est le \\(R^2\\) de l’arbre complet. # Vérifier le paramètre de compléxité doubs.mrt$cptable ## CP nsplit rel error xerror xstd ## 1 0.4369561 0 1.0000000 1.0745075 0.07508352 ## 2 0.1044982 1 0.5630439 0.6770764 0.09501561 Le résumé présente ensuite, pour chaque nœud, les meilleures valeurs de seuil pour le groupement des données. summary(doubs.mrt) ## Call: ## mvpart(form = as.matrix(spe.hel) ~ ., data = env, xv = &quot;1se&quot;, ## xval = nrow(spe.hel), xvmult = 100, margin = 0.01, which = 4, ## legend = FALSE, cp = 0) ## n= 29 ## ## CP nsplit rel error xerror xstd ## 1 0.4369561 0 1.0000000 1.0745075 0.07508352 ## 2 0.1044982 1 0.5630439 0.6770764 0.09501561 ## ## Node number 1: 29 observations, complexity param=0.4369561 ## Means=0.07299,0.2472,0.2581,0.2721,0.07133,0.06813,0.06897,0.07664,0.1488,0.2331,0.113,0.07879,0.1724,0.1366,0.1103,0.08216,0.08751,0.07113,0.07312,0.1345,0.06307,0.04423,0.1015,0.1862,0.07713,0.1623,0.07283, Summed MSE=0.4851823 ## left son=2 (15 obs) right son=3 (14 obs) ## Primary splits: ## alt &lt; 361.5 to the right, improve=0.4369561, (0 missing) ## deb &lt; 23.65 to the left, improve=0.4369561, (0 missing) ## amm &lt; 0.06 to the left, improve=0.3529830, (0 missing) ## nit &lt; 1.415 to the left, improve=0.3513335, (0 missing) ## pen &lt; 1.5 to the right, improve=0.3372429, (0 missing) ## ## Node number 2: 15 observations ## Means=0.1208,0.4463,0.4194,0.4035,0.1104,0.09023,0,0.02108,0.1256,0.2164,0.04392,0.01054,0.107,0.09779,0.06853,0,0.01054,0.01617,0.01054,0.09489,0,0,0,0.08629,0,0,0, Summed MSE=0.3194207 ## ## Node number 3: 14 observations ## Means=0.02179,0.03391,0.08514,0.1313,0.02945,0.04444,0.1429,0.1362,0.1736,0.2509,0.1871,0.1519,0.2425,0.1781,0.1551,0.1702,0.17,0.13,0.1402,0.177,0.1306,0.09163,0.2103,0.2932,0.1598,0.3362,0.1509, Summed MSE=0.2236343 9.2.3 Indicator species On pourrait aussi identifier les espèces indicatrices importantes pour chaque groupe de sites. # Calcul d&#39;une valeur indval pour chaque espèce doubs.mrt.indval &lt;- indval(spe.hel, doubs.mrt$where) # Extraire les espèces indicatrices à chaque noeud doubs.mrt.indval$maxcls[which(doubs.mrt.indval$pval &lt;= 0.05)] ## TRU VAI LOC HOT TOX BAR SPI GOU BRO PER BOU PSO ROT CAR BCO PCH GRE GAR BBO ABL ## 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 ## ANG ## 2 # Extraire leur valeur indval doubs.mrt.indval$indcls[which(doubs.mrt.indval$pval &lt;= 0.05)] ## TRU VAI LOC HOT TOX BAR SPI GOU ## 0.8674301 0.7758443 0.7042392 0.8571429 0.6185282 0.6363569 0.7347359 0.6442950 ## BRO PER BOU PSO ROT CAR BCO PCH ## 0.5533235 0.5449488 0.7857143 0.8070918 0.6352865 0.7307582 0.6428571 0.5000000 ## GRE GAR BBO ABL ANG ## 0.8571429 0.7726181 0.7142857 1.0000000 0.7857143 TRU a la valeur indicatrice la plus élevée (0.867) dans l’ensemble, et est une espèce indicatrice pour la première feuille (alt &gt;= 361.5) de l’arbre. 9.3 Défi 4 Créez un arbre de régression multivarié pour les données mite. * Choisir l’arbre le plus petit à 1 écart type du CVRE minimal. * Quelle est la variance totale expliquée par cet arbre? * Combien y a-t-il de feuilles? * Quels sont les 3 principales espèces discriminantes? Rappel: chargez les données! data(&quot;mite&quot;) data(&quot;mite.env&quot;) Rappel de fonctions utiles: `?`(mvpart() # argument &#39;xv&#39;! ) summary() 9.3.1 Challenge 4: Solution Étape 1: Créer un arbre de régression multivarié. mite.mrt &lt;- mvpart(as.matrix(mite.spe.hel) ~ ., data = mite.env, xv = &quot;1se&quot;, xval = nrow(mite.spe.hel), xvmult = 100, which = 4, legend = FALSE, margin = 0.01, cp = 0, prn = FALSE) Quelle est la variance totale expliquée (\\(R^2\\)) par cet arbre? * \\(1 - 0.748 = 0.252\\), alors l’arbre explique 25.2% de la variation dans la matrice d’abondances. Combien y a-t-il de feuilles? * 2 feuilles Étape 2: Identifier les espèces indicatrices. Quelles sont les espèces indicatrices pour chaque groupe de sites? # Calcul d&#39;une valeur indicatrice pour chaque espèce mite.mrt.indval &lt;- indval(mite.spe.hel, mite.mrt$where) # Extraire les espèces indicatrices à chaque noeud mite.mrt.indval$maxcls[which(mite.mrt.indval$pval &lt;= 0.05)] ## PHTH RARD SSTR Protopl MEGR MPRO TVIE HMIN ## 2 2 2 2 2 2 1 2 ## HMIN2 NPRA TVEL ONOV SUCT LCIL Oribatl1 Ceratoz1 ## 2 2 2 2 2 1 2 1 ## PWIL Galumna1 Stgncrs2 Trhypch1 NCOR SLAT FSET Lepidzts ## 2 2 2 1 1 2 2 2 ## Miniglmn LRUG Ceratoz3 Trimalc2 ## 2 1 1 1 # Extraire leur valeur indval mite.mrt.indval$indcls[which(mite.mrt.indval$pval &lt;= 0.05)] ## PHTH RARD SSTR Protopl MEGR MPRO TVIE HMIN ## 0.5317919 0.5584677 0.2256592 0.2517509 0.5769554 0.1567789 0.3793303 0.6421174 ## HMIN2 NPRA TVEL ONOV SUCT LCIL Oribatl1 Ceratoz1 ## 0.6193076 0.4620892 0.7412296 0.6312483 0.6087557 0.7152107 0.5978167 0.4744997 ## PWIL Galumna1 Stgncrs2 Trhypch1 NCOR SLAT FSET Lepidzts ## 0.3779883 0.5974145 0.3897917 0.4545803 0.4539642 0.2249109 0.6361272 0.2108305 ## Miniglmn LRUG Ceratoz3 Trimalc2 ## 0.1880194 0.6683300 0.3962540 0.4358974 References "],["analyse-discriminante-linéaire.html", "Chapitre 10 Analyse discriminante linéaire 10.1 LDA dans R: Rivière Doubs 10.2 Défi 5", " Chapitre 10 Analyse discriminante linéaire L’analyse discriminante linéaire (LDA ou ADL) est une technique sous contrainte (canonique) qui divise une matrice de réponse en groupes en fonction d’un facteur en trouvant la combinaison de variables qui donne la meilleure séparation possible entre les groupes. Le regroupement est effectué en maximisant la dispersion entre les groupes par rapport à la dispersion à l’intérieur des groupes. Cela vous permet de déterminer dans quelle mesure votre ensemble de variables indépendantes explique un regroupement a priori, qui peut avoir été obtenu à partir d’une analyse de regroupement précédente (voir Atelier 9) ou à partir d’une hypothèse (par exemple, le regroupement est basé sur des sites à différentes latitudes ou différents traitements). La LDA compile des fonctions discriminantes à partir de descripteurs centrés-réduits. Les coefficients obtenus quantifient la contribution relative des variables explicatives sur la discrimination des objets. Les fonctions d’identification peuvent être générées à partir des descripteurs originaux pour classifier de nouvelles données dans des groupes pré-définis. Il existe plusieurs applications utiles de cette capacité à prédire les regroupements, comme la prédiction de l’appartenance d’une espèce de poisson à un groupe selon sa morphologie. On pourrait aussi déterminer si un nouvel article concerne un écosystème terrestre, marin ou d’eau douce selon une classification existante d’articles dans ces biomes effectuée à partir de mots clés de résumés. 10.1 LDA dans R: Rivière Doubs Nous continuerons à travailler avec le jeu de données de poissons de la rivière Doubs pour démontrer comment implémenter une analyse discriminante linéaire dans R. 10.1.1 Créer des groupes a priori Premièrement, nous voulons effectuer une classification à priori qui est indépendante des variables environnementales. Généralement, les variables environnementales changent avec la latitude. Cette notion nous porterait peut-être à poser la question suivante: Si on classifie les sites de la rivière Doubs selon la latitude, à quel point les variables environnementales expliquent-elles bien ces groupements? Pour répondre à cette question, nous classifierons les données d’abondance de poissons de la rivière Doubs en fonction de la latitude pour déterminer à quel point les variables environnementales expliquent ces groupements. Les groupes seront déterminés en divisant l’étendue des latitudes également entre trois groupes, et en assignant chaque site à sa classe de latitude. Commençons par charger les données spatiales des sites: # charger les données spatiales des sites Doubs: spa &lt;- read.csv(&quot;data/doubsspa.csv&quot;, row.names = 1) spa$site &lt;- 1:nrow(spa) # assigner un chiffre par site spa &lt;- spa[-8, ] # enlever le site #8 Ensuite, on peut classifier les sites dans 3 groupes de latitudes: # classification a priori spa$group &lt;- NA # créer colonne &#39;group&#39; spa$group[which(spa$y &lt; 82)] &lt;- 1 spa$group[which(spa$y &gt; 82 &amp; spa$y &lt; 156)] &lt;- 2 spa$group[which(spa$y &gt; 156)] &lt;- 3 Visualisons ces regroupements par latitude: ggplot(data = spa) + geom_point(aes(x = x, y = y, col = as.factor(group)), size = 4) + labs(color = &quot;Groupes&quot;, x = &quot;Longitude&quot;, y = &quot;Latitude&quot;) + scale_color_manual(values = c(&quot;#3b5896&quot;, &quot;#e3548c&quot;, &quot;#ffa600&quot;)) + theme_classic() + # configuration theme(axis.title = element_text(size = 18), axis.text = element_text(size = 16), legend.title = element_text(size = 20), legend.text = element_text(size = 18)) Nous avons maintenant nos groupes a priori. Normalement, nous devons vérifier que les données respectent une condition nécessaire pour l’application d’une LDA: que les matrices de covariance intra-groupe des variables explicatives doivent être homogènes. Au besoin, on peut utiliser la fonction betadisper() du paquet vegan. Pour ce faire, nous utiliserions la fonction betadisper() du paquet vegan pour vérifier l’homogénéité multivariée des variances au sein du groupe avant de procéder, comme vu dans Borcard, Gillet, and Legendre (2011). Pour les besoins de cet atelier, nous allons passer directement à l’analyse LDA. 10.1.2 LDA dans R # faire la LDA LDA &lt;- lda(env, spa$group) Nos sites sont maintenant réorganisés en groupes qui sont les plus distincts possibles, à partir des variables environnementales. On peut visualiser les les sites réorganisés à partir de la LDA, comme suit: # prédire les groupes à partir de la LDA lda.plotdf &lt;- data.frame(group = spa$group, lda = predict(LDA)$x) # Visualiser les sites réorganisés à partir de la LDA ggplot(lda.plotdf) + geom_point(aes(x = lda.LD1, y = lda.LD2, col = factor(group)), size = 4) + labs(color = &quot;Groupes&quot;) + scale_color_manual(values = c(&quot;#3b5896&quot;, &quot;#e3548c&quot;, &quot;#ffa600&quot;)) + theme_classic() + # configuration de la figure pour la rendre plus belle theme(axis.title = element_text(size = 18), axis.text = element_text(size = 16), legend.title = element_text(size = 20), legend.text = element_text(size = 18)) 10.1.3 Exactitude du groupement Une fois que nous avons exécuté la LDA, nous pouvons utiliser le résultat pour déterminer : Comment les sites sont groupés selon les données environnementales, dans le cadre de la LDA; Les probabilités postérieures de l’appartenance des sites aux groupes; Le pourcentage de classification correcte basé sur notre groupement latitudinal. # classification des objets en fonction de la LDA spe.class &lt;- predict(LDA)$class # probabilités que les objets appartiennent à chaque groupe a # posteriori spe.post &lt;- predict(LDA)$posterior # tableau des classifications a priori et prédites (spe.table &lt;- table(spa$group, spe.class)) ## spe.class ## 1 2 3 ## 1 7 0 0 ## 2 0 6 0 ## 3 0 0 16 # proportion de classification correcte diag(prop.table(spe.table, 1)) ## 1 2 3 ## 1 1 1 Tous les sites ont été correctement classifiés (proportion de classification correcte = 1) dans leur groupe de latitude en fonction des variables environnementales. 10.1.4 Prédictions On peut maintenant utiliser la LDA pour classifier de nouveaux sites dans les groupes de latitude, basé sur la relation que nous avons établie entre notre groupement latitudinal et les variables environnementales à l’aide de la LDA. Essayons de prédire la classification de cinq nouveaux sites à l’aide de la LDA: Let us predict the groupings of five new sites dans le jeu de données simulé classifyme.csv en utilisant l’objet LDA que nous avions obtenu ci-dessus. Pour ce faire, nous utiliserons la fonction predict(). # charger les nouvelles données classify.me &lt;- read.csv(&quot;data/classifyme.csv&quot;, header = TRUE) # enlever das classify.me &lt;- subset(classify.me, select = -das) # prédire le groupement des nouvelles données predict.group &lt;- predict(LDA, newdata = classify.me) # prédire la classification pour chaque site predict.group$class ## [1] 1 1 1 3 3 ## Levels: 1 2 3 Nos nouveaux sites, dans l’ordre, ont été classés dans les groupes 1, 1, 1, 3 et 3 respectivement. 10.2 Défi 5 Créez quatre groupes de latitude avec des étendues égales à partir des données mite.xy. Ensuite, faites une LDA sur les données environnementales mite.env des acariens (SubsDens et WatrCont). Quelle proportion de sites ont été classifiés correctement au groupe 1? Au groupe 2? Pour commencer, chargez les données mite.xy: data(mite.xy) Rappel de fonctions utiles: lda() predict() table() diag() Étape 1: Créer quatre groupes de latitude avec des étendues égales. # numéroter les sites mite.xy$site &lt;- 1:nrow(mite.xy) # trouver une étendue égale de latitudes par groupe (max(mite.xy[, 2]) - min(mite.xy[, 2]))/4 ## [1] 2.4 # classifier les sites dans 4 groupes de latitude mite.xy$group &lt;- NA # nouvelle colonne &#39;group&#39; mite.xy$group[which(mite.xy$y &lt; 2.5)] &lt;- 1 mite.xy$group[which(mite.xy$y &gt;= 2.5 &amp; mite.xy$y &lt; 4.9)] &lt;- 2 mite.xy$group[which(mite.xy$y &gt;= 4.9 &amp; mite.xy$y &lt; 7.3)] &lt;- 3 mite.xy$group[which(mite.xy$y &gt;= 7.3)] &lt;- 4 Étape 2: Faire la LDA. LDA.mite &lt;- lda(mite.env[, 1:2], mite.xy$group) Étape 3: Vérifier l’exactitude du groupement. # classification des objects en fonction de la LDA mite.class &lt;- predict(LDA.mite)$class # tableeau de classifications (prior versus predicted) (mite.table &lt;- table(mite.xy$group, mite.class)) ## mite.class ## 1 2 3 4 ## 1 9 4 2 0 ## 2 2 11 4 0 ## 3 1 2 14 2 ## 4 0 0 3 16 On peut maintenant répondre à la question du défi avec cette partie du code: # proportion de classifications exactes diag(prop.table(mite.table, 1)) ## 1 2 3 4 ## 0.6000000 0.6470588 0.7368421 0.8421053 Alors, quelle proportion de sites ont été classifiés correctement au groupe 1? Au groupe 2? 60% des sites ont été classifiés correctement au groupe 1, et 64.7% au groupe 2. References "],["résumé.html", "Chapitre 11 Résumé", " Chapitre 11 Résumé Cet atelier a couvert une série d’analyses sous contraintes, qui nous permettent de tester des hypothèses sur les déterminants des patrons dans une matrice de réponse, telle qu’une matrice décrivant l’abondance d’espèces échantillonnées sur plusieurs sites. Nous pouvons utiliser le RDA, le RDA partiel et le partitionnement de la variation pour quantifier l’importance des différentes variables (ou de groupes de variables) sur une matrice de réponse. Dans de nombreux cas, cette matrice de réponse était une matrice de composition de la communauté de sites x espèces, mais ces techniques ne sont pas limitées à l’écologie des communautés. Nous avons également vu deux méthodes permettant de tester des hypothèses sur les groupements de sites. Nous pouvons utiliser des arbres de régression multivariés (MRT) pour déterminer quelles variables explicatives distinguent les groupes de sites, et décrire comment notre matrice de réponse est organisée dans ces groupes distincts. Si nous disposons déjà d’un groupement de sites a priori, nous pouvons utiliser l’analyse discriminante linéaire (ADL) pour vérifier si ce groupement s’aligne sur les données environnementales, et prédire le groupement de nouveaux sites. "],["ressources-additionelles.html", "Chapitre 12 Ressources additionelles", " Chapitre 12 Ressources additionelles Notre liste de références comprend de nombreux articles et livres utiles pour approfondir les ordinations sous contraintes. Nous recommandons particulièrement Legendre and Legendre (2012) pour une vue approfondie de ces techniques, de leur calcul et de leurs applications potentielles. Nous recommandons également Borcard, Gillet, and Legendre (2011) pour en savoir plus sur la façon dont ces techniques peuvent être implémentées dans R. Malheureusement, nous n’avons pu présenter qu’un sous-ensemble d’ordinations contraintes dans cet atelier. Toutefois, il existe de nombreuses autres options! Celles-ci incluent, mais ne sont pas limitées, aux techniques suivantes: L’analyse des correspondances sous contrainte (CCA ou ACC) est une méthode d’ordination canonique similaire à la RDA qui préserve les distances khi-carré entre les objets (au lieu des distances euclidiennes dans la RDA). Cette méthode est bien adaptée à l’analyse de grands gradients écologiques. L’analyse de corrélation canonique (CCorA) diffère de la RDA dans la mesure où les deux matrices sont considérées comme symétriques, alors que dans la RDA la matrice Y dépend de la matrice X. La principale utilisation de cette technique est de tester la signification de la corrélation entre deux ensembles de données multidimensionnelles, puis d’explorer la structure des données en calculant les corrélations (qui sont les racines carrées des valeurs propres de la CCorA) qui peuvent être trouvées entre les fonctions linéaires de deux groupes de descripteurs. L’analyse de co-inertie (CoIA) est une méthode d’ordination canonique symétrique qui permet de comparer des paires d’ensembles de données qui jouent des rôles équivalents dans l’analyse. La méthode trouve un espace commun sur lequel les objets et les variables de ces ensembles de données peuvent être projetés et comparés. Par rapport à la méthode CCorA, l’analyse de co-inertie n’impose aucune contrainte concernant le nombre de variables dans les deux ensembles, de sorte qu’elle peut être utilisée pour comparer des communautés écologiques même lorsqu’elles sont riches en espèces. L’analyse de co-inertie n’est cependant pas bien adaptée à l’analyse de paires d’ensembles de données qui contiennent les mêmes variables, car l’analyse n’établit pas de correspondance biunivoque entre les variables des deux ensembles de données ; la méthode ne “sait” pas que la première variable est la même dans le premier et le second ensemble de données, et de même pour les autres variables. L’analyse factorielle multiple (MFA) peut être utilisée pour comparer plusieurs ensembles de données décrivant les mêmes objets. La MFA consiste à projeter les objets et les variables de deux ou plusieurs ensembles de données sur une PCA (ou ACP) globale, calculée à partir de tous les ensembles de données, dans laquelle les ensembles reçoivent des poids égaux. `?`(cca # (L&#39;analyse des correspondances sous contrainte) ) `?`(CCorA # L&#39;analyse de corrélation canonique (CCorA) ) help(coinertia, package = ade4) # L&#39;analyse de co-inertie (CoIA) help(mfa, package = ade4) # L&#39;analyse factorielle multiple (MFA) # L&#39;analyse spatiale peut être effectuée à l&#39;aide du paquet # adespatial. Les fonctions propres spatiales peuvent être # calculées avec dbmem(), et elles sont fonctionnellement les # mêmes que celles de PCNM que nous avons vues dans le jeu de # données mite.pcnm de vegan. # https://cran.r-project.org/web/packages/adespatial/index.html References "],["references.html", "Chapitre 13 References", " Chapitre 13 References "]]
