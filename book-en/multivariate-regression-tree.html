<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Multivariate regression tree | Workshop 10: Advanced Multivariate Analyses in R</title>
  <meta name="description" content="Advanced Multivariate Analyses in R" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Multivariate regression tree | Workshop 10: Advanced Multivariate Analyses in R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/qcbsRworkshops/" />
  <meta property="og:image" content="https://github.com/qcbsRworkshops/assets/images/logo/csbq_logo_accueil.png" />
  <meta property="og:description" content="Advanced Multivariate Analyses in R" />
  <meta name="github-repo" content="qcbsRworkshops/workshop10" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Multivariate regression tree | Workshop 10: Advanced Multivariate Analyses in R" />
  
  <meta name="twitter:description" content="Advanced Multivariate Analyses in R" />
  <meta name="twitter:image" content="https://github.com/qcbsRworkshops/assets/images/logo/csbq_logo_accueil.png" />

<meta name="author" content="Developed and maintained by the contributors of the QCBS R Workshop Series" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/images/favicon.ico" type="image/x-icon" />
<link rel="prev" href="variation-partitioning.html"/>
<link rel="next" href="linear-discriminant-analysis.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="assets/qcbs-style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="assets/images/csbq_logo_gray_accueil.png"></a></li>
<link rel="icon" type="image/png" href="assets/images/favicon.ico"/>

<li class="divider"></li>
<li class="part"><span><b>QCBS R Workshop Series</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#code-of-conduct"><i class="fa fa-check"></i><b>0.1</b> Code of conduct</a><ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#expected-behaviour"><i class="fa fa-check"></i><b>0.1.1</b> Expected behaviour</a></li>
<li class="chapter" data-level="0.1.2" data-path="index.html"><a href="index.html#unacceptable-behaviour"><i class="fa fa-check"></i><b>0.1.2</b> Unacceptable behaviour</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i><b>0.2</b> Contributors</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#contributing"><i class="fa fa-check"></i><b>0.3</b> Contributing</a></li>
</ul></li>
<li class="part"><span><b>Advanced Multivariate Analyses in <code>R</code></b></span></li>
<li class="chapter" data-level="1" data-path="learning-objectives.html"><a href="learning-objectives.html"><i class="fa fa-check"></i><b>1</b> Learning objectives</a></li>
<li class="chapter" data-level="2" data-path="preparing-for-the-workshop.html"><a href="preparing-for-the-workshop.html"><i class="fa fa-check"></i><b>2</b> Preparing for the workshop</a></li>
<li class="chapter" data-level="3" data-path="why-advanced-multivariate-methods.html"><a href="why-advanced-multivariate-methods.html"><i class="fa fa-check"></i><b>3</b> Why “advanced multivariate methods”?</a></li>
<li class="chapter" data-level="4" data-path="exploration.html"><a href="exploration.html"><i class="fa fa-check"></i><b>4</b> Exploring the Doubs River dataset</a><ul>
<li class="chapter" data-level="4.1" data-path="exploration.html"><a href="exploration.html#exploring-the-fish-community-dataset"><i class="fa fa-check"></i><b>4.1</b> Exploring the fish community dataset</a></li>
<li class="chapter" data-level="4.2" data-path="exploration.html"><a href="exploration.html#exploring-the-environmental-dataset"><i class="fa fa-check"></i><b>4.2</b> Exploring the environmental dataset</a><ul>
<li class="chapter" data-level="4.2.1" data-path="exploration.html"><a href="exploration.html#collinearity"><i class="fa fa-check"></i><b>4.2.1</b> Collinearity</a></li>
<li class="chapter" data-level="4.2.2" data-path="exploration.html"><a href="exploration.html#standardizing-the-environmental-variables"><i class="fa fa-check"></i><b>4.2.2</b> Standardizing the environmental variables</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Constrained ordinations</b></span></li>
<li class="chapter" data-level="5" data-path="what-are-constrained-ordinations.html"><a href="what-are-constrained-ordinations.html"><i class="fa fa-check"></i><b>5</b> What are “constrained” ordinations?</a></li>
<li class="chapter" data-level="6" data-path="redundancy-analysis.html"><a href="redundancy-analysis.html"><i class="fa fa-check"></i><b>6</b> Redundancy analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="redundancy-analysis.html"><a href="redundancy-analysis.html#how-the-rda-works"><i class="fa fa-check"></i><b>6.1</b> How the RDA works</a></li>
<li class="chapter" data-level="6.2" data-path="redundancy-analysis.html"><a href="redundancy-analysis.html#running-an-rda-in-r"><i class="fa fa-check"></i><b>6.2</b> Running an RDA in R</a><ul>
<li class="chapter" data-level="6.2.1" data-path="redundancy-analysis.html"><a href="redundancy-analysis.html#selecting-variables"><i class="fa fa-check"></i><b>6.2.1</b> Selecting variables</a></li>
<li class="chapter" data-level="6.2.2" data-path="redundancy-analysis.html"><a href="redundancy-analysis.html#significance-testing"><i class="fa fa-check"></i><b>6.2.2</b> Significance testing</a></li>
<li class="chapter" data-level="6.2.3" data-path="redundancy-analysis.html"><a href="redundancy-analysis.html#rda-plot"><i class="fa fa-check"></i><b>6.2.3</b> RDA plot</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="redundancy-analysis.html"><a href="redundancy-analysis.html#challenge-1"><i class="fa fa-check"></i><b>6.3</b> Challenge 1</a><ul>
<li class="chapter" data-level="6.3.1" data-path="redundancy-analysis.html"><a href="redundancy-analysis.html#challenge-1-solution"><i class="fa fa-check"></i><b>6.3.1</b> Challenge 1: Solution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="partial-redundancy-analysis.html"><a href="partial-redundancy-analysis.html"><i class="fa fa-check"></i><b>7</b> Partial Redundancy Analysis</a></li>
<li class="chapter" data-level="8" data-path="variation-partitioning.html"><a href="variation-partitioning.html"><i class="fa fa-check"></i><b>8</b> Variation partitioning</a></li>
<li class="chapter" data-level="9" data-path="multivariate-regression-tree.html"><a href="multivariate-regression-tree.html"><i class="fa fa-check"></i><b>9</b> Multivariate regression tree</a></li>
<li class="chapter" data-level="10" data-path="linear-discriminant-analysis.html"><a href="linear-discriminant-analysis.html"><i class="fa fa-check"></i><b>10</b> Linear discriminant analysis</a></li>
<li class="part"><span><b>Final considerations</b></span></li>
<li class="chapter" data-level="11" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>11</b> Summary</a></li>
<li class="chapter" data-level="12" data-path="additional-resources.html"><a href="additional-resources.html"><i class="fa fa-check"></i><b>12</b> Additional resources</a></li>
<li class="chapter" data-level="13" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>13</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/qcbsRworkshops" target="blank">QCBS R Workshop Series</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Workshop 10: Advanced Multivariate Analyses in <code>R</code></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!------------------------ Hero Image Container --------------------------> 

<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=10.0,initial-scale=1.0">
  <script src="https://kit.fontawesome.com/6a26f47516.js"></script>
  <script src="assets/qcbs-hideOutput.js"></script>
  <link href="assets/qcbs-style.css" rel="stylesheet">
</head>



<div class="hero-image-container"> 
  <img class= "hero-image" src="assets/images/jean-philippe-delberghe-75xPHEQBmvA-unsplash_hero_image.jpg">
</div>
<div id="multivariate-regression-tree" class="section level1">
<h1><span class="header-section-number">Chapter 9</span> Multivariate regression tree</h1>
<p>Multivariate regression tree (MRT) is a constrained clustering
technique. Introduced by De’ath (2002), MRTs allow the partitioning of a
quantitative response matrix by a matrix of explanatory variables
constraining (guiding) on where to divide the data of the response
matrix. RDA and MRT are both regression techniques, the former
explaining the global structure of relationships through a linear model,
the latter better highlighting local structures and interactions among
variables by producing a tree model.</p>
<p>Advantages of the MRT compared to the RDA:</p>
<pre><code>  * does not make assumptions about the shape of the relationships between species and environmental variables (quantitative or categorical), 
  * is robust in dealing with missing values 
  * is robust in dealing with collinearity among the explanatory variables
  * is insensitive to transformations of the explanatory variables, which allows the use of raw values 
  * the outcome, the tree, is easy to interpret, especially to a non-scientist audience.</code></pre>
<p>The MRT technique splits the data into clusters of samples similar in
their species composition based on environmental value thresholds. It
involves two procedures running at the same time: 1) the computation of
the constrained partitioning of the data, and 2) the calculation of the
relative error of the successive partitioning levels by multiple
cross-validations. The function mvpart() from the package mvpart
computes both the partition and the cross-validation.</p>
<p>A quick note on MRT terminology:</p>
<p>Leaf: Terminal group of sites</p>
<p>Node: Point where the data splits into two groups. It is characterized
by a threshold value of an explanatory variable.</p>
<p>Branch: Each group formed by a split</p>
<p><strong>1- Constrained partitioning of the data</strong></p>
<p>First, the method computes all possible partitions of the sites into two
groups. For each quantitative explanatory variable, the sites will be
sorted in the ascending values of the variables; for categorical
variables, the sites will be aggregated by levels to test all
combinations of levels. The method will split the data after the first
object, the second object and so on, and compute the sum of within-group
sum of squared distances to the group mean (within-group SS) for the
response data. The method will retain the partition into two groups
minimizing the within-group SS and the threshold value/level of the
explanatory variable. These steps will be repeated within the two
subgroups formed previously, until all objects form their own group. In
other words, when each leaf of the tree contains one object.</p>
<p><strong>2- Cross-validation and pruning the tree</strong></p>
<p>The mvpart function also performs a cross-validation and identifies the
best predictive tree. The cross-validation procedure consists in using a
subset of the objects to construct the tree, and to allocate the
remaining objects to the groups. In a good predictive tree, objects are
assigned to the appropriate groups. The cross-validated relative error
(CVRE) is the measure of the predictive error. Without cross-validation,
one would retain the number of partitions minimizing the variance not
explained by the tree (i.e. the relative error: the sum of the
within-group SS over all leaves divided by the overall SS of the data).
This is the solution maximizing the R2 so to speak. This approach is
explanatory rather than predictive.</p>
<p>Let’s create a multivariate regression tree on the Doubs data.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="multivariate-regression-tree.html#cb78-1"></a><span class="st">`</span><span class="dt">?</span><span class="st">`</span>(mvpart)</span>
<span id="cb78-2"><a href="multivariate-regression-tree.html#cb78-2"></a></span>
<span id="cb78-3"><a href="multivariate-regression-tree.html#cb78-3"></a><span class="co"># Prepare the data: remove “distance from source”</span></span>
<span id="cb78-4"><a href="multivariate-regression-tree.html#cb78-4"></a>env &lt;-<span class="st"> </span><span class="kw">subset</span>(env, <span class="dt">select =</span> <span class="op">-</span>das)</span>
<span id="cb78-5"><a href="multivariate-regression-tree.html#cb78-5"></a></span>
<span id="cb78-6"><a href="multivariate-regression-tree.html#cb78-6"></a><span class="co"># Create the regression tree</span></span>
<span id="cb78-7"><a href="multivariate-regression-tree.html#cb78-7"></a>doubs.mrt &lt;-<span class="st"> </span><span class="kw">mvpart</span>(<span class="kw">as.matrix</span>(spe.hel) <span class="op">~</span><span class="st"> </span>., env, <span class="dt">legend =</span> <span class="ot">FALSE</span>, </span>
<span id="cb78-8"><a href="multivariate-regression-tree.html#cb78-8"></a>    <span class="dt">margin =</span> <span class="fl">0.01</span>, <span class="dt">cp =</span> <span class="dv">0</span>, <span class="dt">xv =</span> <span class="st">&quot;pick&quot;</span>, <span class="dt">xval =</span> <span class="kw">nrow</span>(spe.hel), </span>
<span id="cb78-9"><a href="multivariate-regression-tree.html#cb78-9"></a>    <span class="dt">xvmult =</span> <span class="dv">100</span>, <span class="dt">which =</span> <span class="dv">4</span>)</span></code></pre></div>
<p>At this point, you will need to select the tree who’s size (number of
groups) is appropriate to the aim of your study from the following
graph. This step requires the argument xv="pick". In other words, you
must prune the tree by picking the best-fit tree. Indeed, a fully
resolved tree is not the desirable outcome. Instead, one is usually
interested in a tree including only informative partitions/groups. It is
possible to have an a-priori idea of the number of potential groups to
be retained as well.</p>
<p><img src="images/cross_validation.png" class="align-center" /></p>
<p>The graph shows the relative error RE (in green) and the cross-validated
relative error CVRE (in blue) of trees of increasing size. The red dot
indicates the solution with the smallest CVRE, and the orange dot shows
the smallest tree within one standard error of CVRE. It has been
suggested that instead of choosing the solution minimizing CVRE, it
would be more parsimonious to opt for the smallest tree for which the
CVRE is within one standard error of the tree with the lowest CVRE
(Breiman et al. 1984). The green bars at the top indicate the number of
times each size was chosen during the cross-validation process.</p>
<p>This graph is interactive, which means you will have to click on the
blue point corresponding your choice of tree size. Once you do so, the
corresponding multivariate regression tree will appear. If you click on
the orange dot, the following tree appears.</p>
<p><img src="images/mrt_1se.png" class="align-center" /></p>
<p>The statistics at the bottom of the figure are: the residual error (the
reciprocal of the R2 of the model, in this case 43.7%), the
cross-validated error, and the standard error. This tree has only two
leaves separated by one node. This node splits the data into two groups
at the threshold altitude value of 361.5m.</p>
<p>Each leaf is characterized by a small barplot showing the abundances of
the species, its number of sites and its relative error.</p>
<p>We can compare this tree with the 10-group solution, as suggested by the
CVRE criterion, or choose a solution in between, e.g. with 4 leaves to
compare.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="multivariate-regression-tree.html#cb79-1"></a><span class="co"># Using the CVRE criterion</span></span>
<span id="cb79-2"><a href="multivariate-regression-tree.html#cb79-2"></a>doubs.mrt.cvre &lt;-<span class="st"> </span><span class="kw">mvpart</span>(<span class="kw">as.matrix</span>(spe.hel) <span class="op">~</span><span class="st"> </span>., env, <span class="dt">legend =</span> <span class="ot">FALSE</span>, </span>
<span id="cb79-3"><a href="multivariate-regression-tree.html#cb79-3"></a>    <span class="dt">margin =</span> <span class="fl">0.01</span>, <span class="dt">cp =</span> <span class="dv">0</span>, <span class="dt">xv =</span> <span class="st">&quot;pick&quot;</span>, <span class="dt">xval =</span> <span class="kw">nrow</span>(spe.hel), </span>
<span id="cb79-4"><a href="multivariate-regression-tree.html#cb79-4"></a>    <span class="dt">xvmult =</span> <span class="dv">100</span>, <span class="dt">which =</span> <span class="dv">4</span>)</span>
<span id="cb79-5"><a href="multivariate-regression-tree.html#cb79-5"></a></span>
<span id="cb79-6"><a href="multivariate-regression-tree.html#cb79-6"></a><span class="co"># Choosing ourself the best number of partitions</span></span>
<span id="cb79-7"><a href="multivariate-regression-tree.html#cb79-7"></a>doubs.mrt<span class="fl">.4</span> &lt;-<span class="st"> </span><span class="kw">mvpart</span>(<span class="kw">as.matrix</span>(spe.hel) <span class="op">~</span><span class="st"> </span>., env, <span class="dt">legend =</span> <span class="ot">FALSE</span>, </span>
<span id="cb79-8"><a href="multivariate-regression-tree.html#cb79-8"></a>    <span class="dt">margin =</span> <span class="fl">0.01</span>, <span class="dt">cp =</span> <span class="dv">0</span>, <span class="dt">xv =</span> <span class="st">&quot;pick&quot;</span>, <span class="dt">xval =</span> <span class="kw">nrow</span>(spe.hel), </span>
<span id="cb79-9"><a href="multivariate-regression-tree.html#cb79-9"></a>    <span class="dt">xvmult =</span> <span class="dv">100</span>, <span class="dt">which =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="images/mrt_cvre.png" class="align-center" /> <img src="images/mrt_4.png" class="align-center" /></p>
<p>The 10-group solution has a high EXPLANATORY power but its predictive
power (indicated by the cross-validated error) is just slightly better
than that of the 2-group solution. The 4-group solution seems to be a
good compromise.</p>
<p>More information can be obtained by looking at the summary output.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="multivariate-regression-tree.html#cb80-1"></a><span class="kw">summary</span>(doubs.mrt)</span></code></pre></div>
<p><img src="images/doubs_mrt_summary.png" class="align-center" /></p>
<p>CP stands for “complexity parameter”, which is the equivalent of the
variance explained by each node. The CP at nsplit 0 is the R2 of the
whole tree. The summary then outlines, for each node, the best threshold
values to split the data. While informative, this output is very dense.
A more detailed and yet more manageable output can be generated by using
the wrapper from the function MRT() of the MVPARTwrap package. Plus,
this other function allows identification of discriminant species.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="multivariate-regression-tree.html#cb81-1"></a><span class="co"># Find discriminant species with MRT results</span></span>
<span id="cb81-2"><a href="multivariate-regression-tree.html#cb81-2"></a>doubs.mrt.wrap &lt;-<span class="st"> </span><span class="kw">MRT</span>(doubs.mrt, <span class="dt">percent =</span> <span class="dv">10</span>, <span class="dt">species =</span> <span class="kw">colnames</span>(spe.hel))</span>
<span id="cb81-3"><a href="multivariate-regression-tree.html#cb81-3"></a><span class="kw">summary</span>(doubs.mrt.wrap)</span>
<span id="cb81-4"><a href="multivariate-regression-tree.html#cb81-4"></a></span>
<span id="cb81-5"><a href="multivariate-regression-tree.html#cb81-5"></a><span class="co"># Extract indval p-values</span></span>
<span id="cb81-6"><a href="multivariate-regression-tree.html#cb81-6"></a>doubs.mrt.indval &lt;-<span class="st"> </span><span class="kw">indval</span>(spe.hel, doubs.mrt<span class="op">$</span>where)</span>
<span id="cb81-7"><a href="multivariate-regression-tree.html#cb81-7"></a>doubs.mrt.indval<span class="op">$</span>pval</span>
<span id="cb81-8"><a href="multivariate-regression-tree.html#cb81-8"></a></span>
<span id="cb81-9"><a href="multivariate-regression-tree.html#cb81-9"></a><span class="co"># Extract indicator species of each node, with its indval</span></span>
<span id="cb81-10"><a href="multivariate-regression-tree.html#cb81-10"></a>doubs.mrt.indval<span class="op">$</span>maxcls[<span class="kw">which</span>(doubs.mrt.indval<span class="op">$</span>pval <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span>)]</span>
<span id="cb81-11"><a href="multivariate-regression-tree.html#cb81-11"></a>doubs.mrt.indval<span class="op">$</span>indcls[<span class="kw">which</span>(doubs.mrt.indval<span class="op">$</span>pval <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span>)]</span></code></pre></div>
<p><img src="images//doubs_mrt_discriminant.png" class="align-center" />
<img src="images//doubs_mrt_finalpart.png" class="align-center" /></p>
<p>The main discriminant species of the first split are TRU, VAI and ABL.
TRU and VAI contribute highly to the left leaf, and ABL is the most
indicative species of the sites at lower altitude (&lt;361.5m). This
output also indicates which sites are included in each leaf.</p>
<p><img src="images//doubs_mrt_indval.png" class="align-center" /></p>
<p>The second part of the code allows us to test the significance of the
indicator value of each species through a permutation test. For each
significant indicator species, we extracted the leaf number and the
indicator value. In this particular case, TRU, VAI and LOC are all
significant species of the left leaf, TRU having the highest indicator
value (0.867).</p>
<p><strong>Challenge 4</strong>: Run the multivariate regression tree for the mite data.
Select the minimum size of tree within one SE of the CVRE. What is the
proportion of variance explained by this tree? How many leaves contain
this tree? What are the discriminant species?</p>
<p><strong>Challenge 4</strong> - Solution</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="multivariate-regression-tree.html#cb82-1"></a>mite.mrt &lt;-<span class="st"> </span><span class="kw">mvpart</span>(<span class="kw">data.matrix</span>(mite.spe.hel) <span class="op">~</span><span class="st"> </span>., mite.env, <span class="dt">legend =</span> <span class="ot">FALSE</span>, </span>
<span id="cb82-2"><a href="multivariate-regression-tree.html#cb82-2"></a>    <span class="dt">margin =</span> <span class="fl">0.01</span>, <span class="dt">cp =</span> <span class="dv">0</span>, <span class="dt">xv =</span> <span class="st">&quot;pick&quot;</span>, <span class="dt">xval =</span> <span class="kw">nrow</span>(mite.spe.hel), </span>
<span id="cb82-3"><a href="multivariate-regression-tree.html#cb82-3"></a>    <span class="dt">xvmult =</span> <span class="dv">100</span>, <span class="dt">which =</span> <span class="dv">4</span>)</span>
<span id="cb82-4"><a href="multivariate-regression-tree.html#cb82-4"></a><span class="kw">summary</span>(mite.mrt)</span>
<span id="cb82-5"><a href="multivariate-regression-tree.html#cb82-5"></a></span>
<span id="cb82-6"><a href="multivariate-regression-tree.html#cb82-6"></a>mite.mrt.wrap &lt;-<span class="st"> </span><span class="kw">MRT</span>(mite.mrt, <span class="dt">percent =</span> <span class="dv">10</span>, <span class="dt">species =</span> <span class="kw">colnames</span>(mite.spe.hel))</span>
<span id="cb82-7"><a href="multivariate-regression-tree.html#cb82-7"></a><span class="kw">summary</span>(mite.mrt.wrap)</span>
<span id="cb82-8"><a href="multivariate-regression-tree.html#cb82-8"></a></span>
<span id="cb82-9"><a href="multivariate-regression-tree.html#cb82-9"></a>mite.mrt.indval &lt;-<span class="st"> </span><span class="kw">indval</span>(mite.spe.hel, mite.mrt<span class="op">$</span>where)</span>
<span id="cb82-10"><a href="multivariate-regression-tree.html#cb82-10"></a>mite.mrt.indval<span class="op">$</span>pval</span>
<span id="cb82-11"><a href="multivariate-regression-tree.html#cb82-11"></a></span>
<span id="cb82-12"><a href="multivariate-regression-tree.html#cb82-12"></a>mite.mrt.indval<span class="op">$</span>maxcls[<span class="kw">which</span>(mite.mrt.indval<span class="op">$</span>pval <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span>)]</span>
<span id="cb82-13"><a href="multivariate-regression-tree.html#cb82-13"></a>mite.mrt.indval<span class="op">$</span>indcls[<span class="kw">which</span>(mite.mrt.indval<span class="op">$</span>pval <span class="op">&lt;=</span><span class="st"> </span><span class="fl">0.05</span>)]</span></code></pre></div>
<p>25.6% of the variation in the mite species assemblage across sites is
explained by the partition of the sites based on water content of the
substrate (at 385.1 mg/l). LCIL is a discriminant species of sites with
higher water content, and has an indicator value of 0.715.</p>

</div>
<hr>
<center> 
  <div class="footer">
      All the content of the workshop series is under a <a href="https://creativecommons.org/licenses/by-nc/2.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  </div>
</center>
            </section>

          </div>
        </div>
      </div>
<a href="variation-partitioning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-discriminant-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
